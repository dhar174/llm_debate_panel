{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvqEP-kxAmiX",
        "outputId": "86bf1407-9870-408e-af83-19b296f0167c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on CoLab\n",
            "langchain_community already installed.\n",
            "langchain already installed.\n",
            "openai already installed.\n",
            "python-dotenv already installed.\n",
            "tiktoken already installed.\n",
            "langchain_openai already installed.\n",
            "google-colab already installed.\n",
            "langgraph already installed.\n",
            "chromadb already installed.\n",
            "langchain_experimental already installed.\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.40)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.2.74)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.40)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.16)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.53)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.15.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "!pip install -qU \"langchain-community>=0.2.11\" tavily-python\n",
        "key = userdata.get('TAVILY_API_KEY')\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = key\n",
        "def check_and_install(package_name):\n",
        "    try:\n",
        "        subprocess.check_output(['pip', 'show', package_name])\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"{package_name} not found, installing...\")\n",
        "        subprocess.check_output(['pip', 'install', package_name])\n",
        "    else:\n",
        "        print(f\"{package_name} already installed.\")\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "\n",
        "check_and_install('langchain_community')\n",
        "check_and_install('langchain')\n",
        "check_and_install('openai')\n",
        "check_and_install('python-dotenv')\n",
        "check_and_install('tiktoken')\n",
        "check_and_install('langchain_openai')\n",
        "check_and_install('google-colab')\n",
        "check_and_install('langgraph')\n",
        "check_and_install('chromadb')\n",
        "check_and_install('langchain_experimental')\n",
        "!pip install --upgrade langchain\n",
        "!pip install langgraph\n",
        "!pip install chromadb\n",
        "!pip install -U pydantic\n",
        "\n",
        "oai_key = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1NHB1z5BNWo",
        "outputId": "687a6206-4909-4614-8056-4d8e43c7b2ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-2435ff6d357e>:108: PydanticDeprecatedSince20: Pydantic V1 style `@root_validator` validators are deprecated. You should migrate to Pydantic V2 style `@model_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @root_validator(pre=True)\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field, validator, model_validator\n",
        "from typing import Dict, Optional\n",
        "from langchain_core.language_models.chat_models import BaseChatModel\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "import uuid\n",
        "from typing import Annotated, List, Optional, OrderedDict, Tuple, Union\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CleaningMetadata(BaseModel):\n",
        "    \"\"\"Metadata about the data cleaning actions taken.\"\"\"\n",
        "    steps_taken: list[str] = Field(description=\"List of cleaning steps performed.\")\n",
        "    data_description_after_cleaning: str = Field(description=\"Brief description of the dataset after cleaning.\")\n",
        "\n",
        "\n",
        "class InitialDescription(BaseModel):\n",
        "    \"\"\"Initial description of the dataset.\"\"\"\n",
        "    dataset_description: str = Field(description=\"Brief description of the dataset.\")\n",
        "    data_sample: Optional[str] = Field(description=\"Sample of the data (first few rows).\")\n",
        "\n",
        "class AnalysisInsights(BaseModel):\n",
        "    \"\"\"Insights from the exploratory data analysis.\"\"\"\n",
        "    summary: str = Field(description=\"Overall summary of EDA findings.\")\n",
        "    correlation_insights: str = Field(description=\"Key correlation insights identified.\")\n",
        "    anomaly_insights: str = Field(description=\"Anomalies or interesting patterns detected.\")\n",
        "    recommended_visualizations: list[str] = Field(description=\"List of recommended visualizations to illustrate findings.\")\n",
        "\n",
        "\n",
        "\n",
        "class VisualizationResults(BaseModel):\n",
        "    \"\"\"Results from the visualization generation.\"\"\"\n",
        "    visualizations: List[\n",
        "        dict\n",
        "    ] = Field(\n",
        "        description=\"List of visualizations generated. Each dictionary should have the plot type and the base64 encoded image\"\n",
        "    )\n",
        "    # visualizations: Optional[str] = Field(description=\"Visualization Results\")\n",
        "\n",
        "# Define the ReportResults class\n",
        "class ReportResults(BaseModel):\n",
        "    \"\"\"Results from the report generation.\"\"\"\n",
        "    report_path: str = Field(description=\"Path to the generated report file.\")\n",
        "    # Add other fields as needed, e.g., for different report formats\n",
        "\n",
        "\n",
        "class DataQueryParams(BaseModel):\n",
        "    \"\"\"\n",
        "Parameters for querying the DataFrame.\n",
        "\n",
        "Attributes:\n",
        "  columns: List[str] - List of columns to include in the output.\n",
        "  filter_column: Optional[str] - Column to apply the filter on.\n",
        "  filter_value: Optional[str] - Value to filter the rows by.\n",
        "  operation: str - Operation to perform.\n",
        "\n",
        "    \"\"\"\n",
        "    columns: List[str] = Field(..., description=\"List of columns to include in the output\")\n",
        "    filter_column: Optional[str] = Field(None, description=\"Column to apply the filter on\")\n",
        "    filter_value: Optional[str] = Field(None, description=\"Value to filter the rows by\")\n",
        "    operation: str = Field(\"select\", description=\"Operation to perform: 'select', 'sum', 'mean', 'count', 'max', 'min', 'median', etc.\")\n",
        "\n",
        "\n",
        "schema_extra_cols={\n",
        "            \"anyOf\": [\n",
        "                {\"type\": \"integer\"},\n",
        "                {\"type\": \"array\", \"items\": {\"type\": \"integer\"}},\n",
        "                {\"type\": \"array\", \"items\": {\"type\": \"integer\"}, \"minItems\": 2, \"maxItems\": 2},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "schema_extra_cells={\n",
        "            \"anyOf\": [\n",
        "                {\"type\": \"array\", \"items\": {\"type\": \"integer\"}, \"minItems\": 2, \"maxItems\": 2},\n",
        "                {\"type\": \"null\"},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "class GetDataParams(BaseModel):\n",
        "    \"\"\"\n",
        "Parameters for retrieving data from the DataFrame.\n",
        "\n",
        "Attributes:\n",
        "  df_id: DataFrame ID in the global registry (as a string)\n",
        "  index: (as `Union[int, List[int], Tuple[int, int]]`) Can be: An integer (single row), a list of integers (multiple rows), or a tuple (start, end) for a row range.\n",
        "  columns: A string (single column), a list of strings (multiple columns), or \"all\" for all columns (default: \"all\").\n",
        "  cells: A list of (row_index, column_name) tuples to retrieve specific cell values (as `Optional[List[Tuple[int, str]]]`).\n",
        "    \"\"\"\n",
        "    df_id: str = Field(..., description=\"DataFrame ID in the global registry.\")\n",
        "    index: Union[int, List[int], Tuple[int, int]] = Field(..., description=\"An integer (single row), a list of integers (multiple rows), or a tuple (start, end) for a row range.\", json_schema_extra=schema_extra_cols)\n",
        "    columns: Union[str, List[str]] = Field(\"all\", description=\"A string (single column), a list of strings (multiple columns), or 'all' for all columns (default: 'all').\")\n",
        "    cells: Optional[List[Tuple[int, str]]] = Field(None, description=\"A list of (row_index, column_name) tuples to retrieve specific cell values.\",json_schema_extra={\n",
        "            \"type\": \"array\",  # Specify it's an array\n",
        "            \"items\": {  # Define the schema for items within the array\n",
        "                \"type\": \"array\",  # Each item is an array (tuple)\n",
        "                \"items\": [\n",
        "                    {\"type\": \"integer\"},  # First element of the tuple is an integer (row_index)\n",
        "                    {\"type\": \"string\"},  # Second element is a string (column_name)\n",
        "                ],\n",
        "                \"minItems\": 2,  # Enforce tuple length\n",
        "                \"maxItems\": 2,\n",
        "            },\n",
        "        },)\n",
        "\n",
        "    @model_validator(mode='before')\n",
        "    def validate_index(cls, values):\n",
        "        \"\"\"Validate and transform the 'index' field.\"\"\"\n",
        "        index = values.get('index')\n",
        "        if not isinstance(index, (int, list, tuple)):\n",
        "            raise ValueError(\"Invalid 'index' type. Must be int, list, or tuple.\")\n",
        "        if isinstance(index, tuple) and len(index) != 2:\n",
        "            raise ValueError(\"Invalid tuple length for 'index'. Must be a 2-tuple for range.\")\n",
        "        if isinstance(index, list) and not all(isinstance(i, int) for i in index):\n",
        "            raise ValueError(\"Invalid list elements for 'index'. Must contain only integers.\")\n",
        "\n",
        "        # if isinstance(index, int):\n",
        "        #     values[\"index\"] = [index]\n",
        "        return values\n",
        "\n",
        "class DataFrameRegistry:\n",
        "    def __init__(self, capacity=20):\n",
        "        self.registry: Dict[str, dict] = {}  # Changed from Dict[str, pd.DataFrame] to Dict[str, dict]\n",
        "        self.df_id_to_raw_path: Dict[str, str] = {}\n",
        "        self.cache = OrderedDict()  # Use OrderedDict for LRU cache\n",
        "        self.capacity = capacity\n",
        "\n",
        "    def register_dataframe(self, df=None, df_id=None, raw_path=\"\"):\n",
        "        if df_id is None:\n",
        "            df_id = str(uuid.uuid4())\n",
        "        if raw_path == \"\":\n",
        "            raw_path = WORKING_DIRECTORY / f\"{df_id}.csv\"\n",
        "        self.registry[df_id] = {\"df\": df, \"raw_path\": raw_path}\n",
        "        self.df_id_to_raw_path[df_id] = raw_path\n",
        "        if df is not None:  # Add to cache if DataFrame is provided\n",
        "            self.cache[df_id] = df\n",
        "            if len(self.cache) > self.capacity:\n",
        "                self.cache.popitem(last=False)\n",
        "        return df_id\n",
        "\n",
        "    def get_dataframe(self, df_id: str, load_if_not_exists=False):\n",
        "        if df_id in self.cache:\n",
        "            # Move the accessed DataFrame to the end of the OrderedDict\n",
        "            self.cache.move_to_end(df_id)\n",
        "            return self.cache[df_id]\n",
        "        # If not in cache, load from registry or file\n",
        "        df = super().get_dataframe(df_id, load_if_not_exists)\n",
        "        if df:\n",
        "            # Add the loaded DataFrame to the cache\n",
        "            self.cache[df_id] = df\n",
        "            # If cache exceeds capacity, evict the LRU entry\n",
        "            if len(self.cache) > self.capacity:\n",
        "                self.cache.popitem(last=False)  # Remove from the beginning\n",
        "        return df\n",
        "    def remove_dataframe(self, df_id: str):\n",
        "        if df_id in self.registry:\n",
        "            del self.registry[df_id]\n",
        "            if df_id in self.cache:\n",
        "                del self.cache[df_id]\n",
        "            del self.df_id_to_raw_path[df_id]\n",
        "    def get_raw_path_from_id(self, df_id: str):\n",
        "        return self.df_id_to_raw_path.get(df_id)\n",
        "\n",
        "global_df_registry = DataFrameRegistry()\n",
        "\n",
        "class State(AgentState):\n",
        "  next: str\n",
        "  user_prompt: str\n",
        "  df_ids: List[str] = Field(default_factory=list) # Use a list to store df_ids\n",
        "  _config: Optional[RunnableConfig] = None\n",
        "  initial_description: Optional[InitialDescription] = None\n",
        "  cleaning_metadata: Optional[CleaningMetadata] = None\n",
        "  analysis_insights: Optional[AnalysisInsights] = None\n",
        "  initial_analysis_agent: Optional[BaseChatModel] = None\n",
        "  data_cleaner_agent: Optional[BaseChatModel] = None\n",
        "  analyst_agent: Optional[BaseChatModel] = None\n",
        "  initial_analysis_complete: Optional[bool] = False\n",
        "  data_cleaning_complete: Optional[bool] = False\n",
        "  analyst_complete: Optional[bool] = False\n",
        "  file_writer_complete: Optional[bool] = False\n",
        "  _count_: int = 0\n",
        "  _id_: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
        "  visualization_results: Optional[VisualizationResults] = None\n",
        "  visualization_complete: Optional[bool] = False\n",
        "  report_results: Optional[ReportResults] = None\n",
        "  report_generator_complete: Optional[bool] = False\n",
        "\n",
        "# class AState(AgentState):\n",
        "#   next: str\n",
        "#   user_prompt: str\n",
        "#   initial_description: Optional[InitialDescription] = None\n",
        "#   cleaning_metadata: Optional[CleaningMetadata] = None\n",
        "#   analysis_insights: Optional[AnalysisInsights] = None\n",
        "\n",
        "data_cleaner_prompt_template = PromptTemplate(\n",
        "    input_variables=['dataset_description', 'data_sample', 'tool_descriptions', 'output_format', 'available_df_ids'],\n",
        "    template=\"\"\"You are a Data Cleaner Agent equipped with tools to clean and preprocess a dataset.\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    Here's a description of the dataset: {dataset_description}\n",
        "    Here's a sample of the data (first few rows):\n",
        "    {data_sample}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    You have access to a tool called `query_dataframe` for querying the DataFrame.\n",
        "    Refer to the tool's docstring for detailed usage instructions and examples.\n",
        "    You can get the column names with `get_column_names`, and get any specified data from the dataframe using `get_data`.\n",
        "\n",
        "    Identify potential issues like missing values, outliers, incorrect data types, and inconsistencies.\n",
        "    Propose and execute a cleaning strategy, step-by-step, using the provided tools.\n",
        "    For each step, clearly state the tool you are using and the parameters.\n",
        "    Explain your reasoning for each cleaning step.\n",
        "\n",
        "    Example Plan & Execution:\n",
        "    Step 1: Check for missing values in each column using the 'CheckMissingValues' tool with input 'df_id'.\n",
        "    Step 2: If 'Age' column has missing values, fill them using the 'FillMissingMedian' tool with input 'df_id' and 'column_name' as 'Age'.\n",
        "    ... and so on.\n",
        "\n",
        "    After cleaning, summarize the actions taken and describe the current state of the dataset in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "\n",
        "    Let's begin! What is your data cleaning plan and execution using tools, and structured output?\n",
        "    \"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d9eiQorB37h"
      },
      "outputs": [],
      "source": [
        "\n",
        "analyst_prompt_template_initial = PromptTemplate(\n",
        "    input_variables=['user_prompt', 'tool_descriptions', 'output_format','available_df_ids'],\n",
        "    template=\"\"\"You are an Data Describer and Sampler. Your role is to perform exploratory data analysis (EDA) on a dataset.\n",
        "    Here's a text description of the dataset: {user_prompt}\n",
        "\n",
        "    First, we need a basic description of the dataset, along with a sample of the data, to pass to the Data Cleaner Agent.\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "\n",
        "    Describe the dataset in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "    FIRST, think of a step by step plan for how to proceed with collecting the data you need, when to stop collecting, and how and when to report back in the requested format.\n",
        "\n",
        "    Using your tools in a conservative manner, please 1. Write a text description of the dataset based on a few strategically used tool calls, and write it to dataset_description attribute.\n",
        "    Then, 2. use your tools to produce a sample of the data for the data_sample attribute.\n",
        "\n",
        "    Do not make unnecessary or repeated tool calls! Report straight to the Supervisor with the expected output format.\n",
        "\n",
        "    After performing any necessary tool calls, IMMEDIATELY output your final answer in the specified format. Do NOT make any further tool calls!\n",
        "    You do not need to perform the functions of other agents, do your job and submit the results.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "analyst_prompt_template_main = PromptTemplate(\n",
        "    input_variables=['cleaned_dataset_description', 'cleaning_metadata', 'tool_descriptions', 'output_format','available_df_ids'],\n",
        "    template=\"\"\"You are an Analyst Agent. Your role is to perform exploratory data analysis (EDA) on a cleaned dataset.\n",
        "    Here's a description of the cleaned dataset: {cleaned_dataset_description}\n",
        "    Here's metadata about the data cleaning actions taken: {cleaning_metadata}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    You have access to a tool called `query_dataframe` for querying the DataFrame.\n",
        "    Refer to the tool's docstring for detailed usage instructions and examples.\n",
        "    You can get the column names with `get_column_names`, and get any specified data from the dataframe using `get_data`.\n",
        "\n",
        "    Perform EDA to understand the dataset. Include:\n",
        "    - Descriptive statistics (mean, median, mode, standard deviation, etc.) for relevant columns.\n",
        "    - Identify potential correlations between features.\n",
        "    - Highlight any anomalies or interesting patterns you find.\n",
        "    - Reason step-by-step about your analysis (Chain-of-Thought).\n",
        "    - Recommend visualizations that would best illustrate your findings.\n",
        "\n",
        "    Output should be a summary of your EDA findings, insights, and recommended visualizations, based on your tool usage, all written into the\n",
        "    {output_format} class.\n",
        "\n",
        "    Let's begin! What are your EDA insights and visualization recommendations using tools?\n",
        "\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "\n",
        "file_writer_prompt_template = PromptTemplate(\n",
        "    input_variables=['file_name', 'content', 'file_type','tool_descriptions','available_df_ids'],\n",
        "    template= \"\"\"You are an agent that specializes in writing data to a file in the format of {file_type}. You are one member of a data analysis team. You ONLY write content as requested in a analyst-friendly manner. Leaver other tasks to other agents on the team.\n",
        "    You have the following tools at your disposal:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "\n",
        "    Write the following content to a file named {file_name}:\n",
        "    {content}\n",
        "    \"\"\",\n",
        ")\n",
        "visualization_prompt_template = PromptTemplate(\n",
        "    input_variables=[\n",
        "        \"cleaned_dataset_description\",\n",
        "        \"analysis_insights\",\n",
        "        \"tool_descriptions\",\n",
        "        \"output_format\",\n",
        "        \"available_df_ids\",\n",
        "    ],\n",
        "    template=\"\"\"You are a Visualization Agent equipped with tools to create visualizations.\n",
        "    Here's a description of the cleaned dataset: {cleaned_dataset_description}\n",
        "    Here are the insights from the Analyst Agent and the list of visualizations to create: {analysis_insights}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "\n",
        "    Create the visualizations step-by-step, using the provided tools.\n",
        "    For each step, clearly state the tool you are using and the parameters.\n",
        "    Explain your reasoning for each visualization.\n",
        "\n",
        "    After creating the visualizations, summarize the actions taken and describe the current state of the visualizations in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "\n",
        "    Let's begin!\n",
        "    What is your visualization plan and execution using tools, and structured output?\n",
        "    \"\"\",\n",
        ")\n",
        "report_generator_prompt_template = PromptTemplate(\n",
        "    input_variables=[\n",
        "        \"cleaning_metadata\",\n",
        "        \"analysis_insights\",\n",
        "        \"visualization_results\",\n",
        "        \"tool_descriptions\",\n",
        "        \"output_format\",\n",
        "        \"available_df_ids\",\n",
        "    ],\n",
        "    template=\"\"\"You are a Report Generator Agent equipped with tools to generate reports.\n",
        "    Here's the metadata about the data cleaning actions taken: {cleaning_metadata}\n",
        "    Here are the insights from the Analyst Agent: {analysis_insights}\n",
        "    Here are the visualization results: {visualization_results}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    Generate a structured report that combines textual explanations, statistics, and visualizations.\n",
        "    Explain your reasoning for the report structure.\n",
        "\n",
        "    After generating the report, summarize the actions taken and describe the current state of the report in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "\n",
        "    Let's begin!\n",
        "    What is your report generation plan and execution using tools, and structured output?\n",
        "    \"\"\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzo9i8HtDrmO"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool, InjectedToolArg\n",
        "from langchain.tools import Tool\n",
        "from tempfile import TemporaryDirectory\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import io\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "_TEMP_DIRECTORY = TemporaryDirectory()\n",
        "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
        "\n",
        "@tool(name_or_callable=\"GetDataframeSchema\",response_format=\"content_and_artifact\")\n",
        "def get_dataframe_schema() -> tuple[str, dict]:\n",
        "    \"\"\"\n",
        "    Return a summary of the DataFrame's schema and sample data.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing a summary of the DataFrame's schema and sample data.\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        schema = {\n",
        "            \"columns\": list(df.columns),\n",
        "            \"dtypes\": df.dtypes.astype(str).to_dict(),\n",
        "            \"sample\": df.head(3).to_dict(orient=\"records\")\n",
        "        }\n",
        "        return \"\", {\"schema\": schema}\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", {}\n",
        "\n",
        "@tool(\"GetColumnNames\")\n",
        "def get_column_names(df_id: str) -> str:\n",
        "    \"\"\"Useful to get the names of the columns in the current DataFrame.\n",
        "\n",
        "    Retrieves the names of all columns in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "\n",
        "    Returns:\n",
        "        A comma-separated string of column names.\n",
        "\n",
        "    Example:\n",
        "        If the DataFrame has columns 'Name', 'Age', and 'City', the output would be:\n",
        "        \"Name, Age, City\"\n",
        "    \"\"\"\n",
        "    print(f\"Getting column names from {df_id}/n\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    if df is None:\n",
        "      try:\n",
        "        raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "        df = pd.read_csv(raw_path)\n",
        "        global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "      except Exception as e:\n",
        "        return f\"Error loading DataFrame: {e}\"\n",
        "      pass\n",
        "    pprint(f\"Column names: {', '.join(df.columns.tolist())} /n\")\n",
        "    return \", \".join(df.columns.tolist())\n",
        "\n",
        "@tool(\"CheckMissingValues\")\n",
        "def check_missing_values(df_id: str) -> str:\n",
        "    \"\"\"Checks for missing values in a pandas DataFrame and returns a summary.\n",
        "\n",
        "    Checks for missing values in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "\n",
        "    Returns:\n",
        "        A summary of missing values in each column.\n",
        "    \"\"\"\n",
        "    pprint(f\"Checking missing values in {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "\n",
        "    if df is None:\n",
        "      try:\n",
        "        raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "        df = pd.read_csv(raw_path)\n",
        "        global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "      except Exception as e:\n",
        "        return f\"Error loading DataFrame: {e}\"\n",
        "      pass\n",
        "\n",
        "    missing_values = df.isnull().sum()\n",
        "    pprint(f\"Missing values: {missing_values}\")\n",
        "    return missing_values.to_string()\n",
        "\n",
        "@tool(\"DropColumn\")\n",
        "def drop_column(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Drops a specified column from the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the column to drop.\n",
        "\n",
        "    Returns:\n",
        "        A message indicating whether the column was dropped successfully.\n",
        "    \"\"\"\n",
        "    pprint(f\"Dropping column {column_name} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "\n",
        "    try:\n",
        "        if df is None:\n",
        "          try:\n",
        "            raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "            df = pd.read_csv(raw_path)\n",
        "            global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "          except Exception as e:\n",
        "            return f\"Error loading DataFrame: {e}\"\n",
        "          pass\n",
        "        df_dropped = df.drop(columns=[column_name])\n",
        "        return \"Column dropped successfully. New columns: \" + \", \".join(df_dropped.columns.tolist())\n",
        "    except Exception as e:\n",
        "        return f\"Error dropping column: {e}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def delete_rows(df_id: str, conditions: Union[str, List[str], Dict], inplace: bool = True) -> str:\n",
        "    \"\"\"\n",
        "    Deletes rows from the DataFrame based on specified conditions.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        conditions: The conditions for deleting rows. Can be a string, a list of strings, or a dictionary.\n",
        "        inplace: Whether to delete rows inplace or return a new DataFrame. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        A message indicating the result of the operation.\n",
        "\n",
        "    Examples:\n",
        "        * Delete rows where 'Age' is greater than 30:\n",
        "        ```python\n",
        "        delete_rows(df_id='my_df', conditions='Age > 30')\n",
        "        ```\n",
        "        * Delete rows where 'Age' is greater than 30 and 'Gender' is Female:\n",
        "        ```python\n",
        "        delete_rows(df_id='my_df', conditions={\"and\": [\"Age > 30\", \"Gender == 'Female'\"]})\n",
        "        ```\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "          try:\n",
        "            raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "            df = pd.read_csv(raw_path)\n",
        "            global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "          except Exception as e:\n",
        "            return f\"Error loading DataFrame: {e}\"\n",
        "          pass\n",
        "\n",
        "        if isinstance(conditions, str):\n",
        "            conditions = [conditions]\n",
        "\n",
        "        if isinstance(conditions, list):\n",
        "            for condition in conditions:\n",
        "                df = df.query(condition)\n",
        "        elif isinstance(conditions, dict):\n",
        "            #Gemini, please write the logic to handle dictionary conditions:\n",
        "            for condition_type, condition_list in conditions.items():\n",
        "                if condition_type == \"and\":\n",
        "                    for condition in condition_list:\n",
        "                        df = df.query(condition)\n",
        "                        pass\n",
        "                elif condition_type == \"or\":\n",
        "                    for condition in condition_list:\n",
        "                        df = df.query(condition)\n",
        "                    pass\n",
        "                elif condition_type == \"not\":\n",
        "                    for condition in condition_list:\n",
        "                        df = df.query(condition)\n",
        "                    pass\n",
        "                else:\n",
        "                    return \"Error: Invalid condition type.\"\n",
        "\n",
        "\n",
        "            pass\n",
        "        else:\n",
        "            return \"Error: Invalid conditions format.\"\n",
        "\n",
        "        if inplace:\n",
        "            df.drop(df.index, inplace=True)\n",
        "            return \"Rows deleted successfully.\"\n",
        "        else:\n",
        "            return df.to_json()  # Or return a summary\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error deleting rows: {e}\"\n",
        "\n",
        "\n",
        "@tool(\"FillMissingMedian\")\n",
        "def fill_missing_median(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Fills missing values in a specified column with the median.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the column to fill.\n",
        "\n",
        "    Returns:\n",
        "        A message indicating the result of the operation.\n",
        "    \"\"\"\n",
        "    pprint(f\"Filling missing values in column {column_name} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "        pass\n",
        "      median_value = df[column_name].median()\n",
        "      df_filled = df[column_name].fillna(median_value) # Only fill series for brevity\n",
        "      return f\"Missing values in column '{column_name}' filled with median: {median_value}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error filling missing values: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "# Define tools as LangChain Tools\n",
        "data_cleaning_tools = [\n",
        "    Tool(\n",
        "        name=\"GetDataFrameSchema\",\n",
        "        func=get_dataframe_schema,\n",
        "        description=\"Useful to get a summary of the DataFrame's schema and sample data.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"GetColumnNames\",\n",
        "        func=get_column_names,\n",
        "        description=\"Useful to get the names of the columns in the current DataFrame. Input should be 'df_id'.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"CheckMissingValues\",\n",
        "        func=check_missing_values,\n",
        "        description=\"Useful to check for missing values in the DataFrame. Input should be 'df_id'.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"DropColumn\",\n",
        "        func=drop_column,\n",
        "        description=\"Useful to drop a column from the DataFrame. Input should be 'df_id' and 'column_name'.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"DeleteRows\",\n",
        "        func=delete_rows,\n",
        "        description=\"Useful to delete rows from the DataFrame based on specified conditions. Input should be 'df_id', 'conditions', and 'inplace'.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"FillMissingMedian\",\n",
        "        func=fill_missing_median,\n",
        "        description=\"Useful to fill missing values in a specific column using the median. Input should be 'df_id' and 'column_name'.\",\n",
        "    ),\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "8Yb-OklIFuFw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans # Example - if you want to include sklearn\n",
        "\n",
        "\n",
        "\n",
        "from typing import Union, Tuple\n",
        "\n",
        "\n",
        "from langchain.agents import tool\n",
        "\n",
        "@tool(name_or_callable=\"QueryDataframe\",response_format=\"content_and_artifact\")\n",
        "def query_dataframe(params: DataQueryParams, df_id: str) -> tuple[str, dict]:\n",
        "    \"\"\"\n",
        "    Query the DataFrame based on specified columns, filter, and operation.\n",
        "\n",
        "    Use the `query_dataframe` tool effectively to explore and analyze the data.\n",
        "    Remember to provide the correct `df_id` when using the tool.\n",
        "\n",
        "    Args:\n",
        "        params: A DataQueryParams object defining the query.\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing a status message and a dictionary with the query result as a JSON artifact.\n",
        "\n",
        "    Examples:\n",
        "        * Select specific columns:\n",
        "        ```python\n",
        "        params = DataQueryParams(columns=[\"Name\", \"Age\"])\n",
        "        result = query_dataframe(params, df_id)\n",
        "        ```\n",
        "\n",
        "        * Filter rows based on a condition:\n",
        "        ```python\n",
        "        params = DataQueryParams(columns=[\"Sales\"], filter_column=\"Region\", filter_value=\"North\")\n",
        "        result = query_dataframe(params, df_id)\n",
        "        ```\n",
        "\n",
        "        * Calculate the sum of a column:\n",
        "        ```python\n",
        "        params = DataQueryParams(columns=[\"Sales\"], operation=\"sum\")\n",
        "        result = query_dataframe(params, df_id)\n",
        "        ```\n",
        "\n",
        "        * Calculate the mean of a column for a specific group:\n",
        "        ```python\n",
        "        params = DataQueryParams(columns=[\"Salary\"], filter_column=\"Department\", filter_value=\"Marketing\", operation=\"mean\")\n",
        "        result = query_dataframe(params, df_id)\n",
        "        ```\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            try:\n",
        "              raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "              df = pd.read_csv(raw_path)\n",
        "              global_df_registry.register_dataframe(df, df_id, raw_path, raw_path)\n",
        "            except Exception as e:\n",
        "                return f\"Error loading DataFrame: {e}\"\n",
        "            pass\n",
        "\n",
        "        # Validate the column exists\n",
        "        if params.filter_column and params.filter_column not in df.columns:\n",
        "            return \"Error: Filter column does not exist.\", {}\n",
        "\n",
        "        # Filter the DataFrame\n",
        "        if params.filter_column:\n",
        "            filtered_df = df[df[params.filter_column] == params.filter_value]\n",
        "        else:\n",
        "            filtered_df = df\n",
        "\n",
        "        # Perform the operation\n",
        "        if params.operation == \"select\":\n",
        "            result = filtered_df[params.columns].to_dict(orient=\"records\")\n",
        "        elif params.operation == \"sum\":\n",
        "            result = filtered_df[params.columns].sum(numeric_only=True).to_dict()\n",
        "        elif params.operation == \"mean\":\n",
        "            result = filtered_df[params.columns].mean(numeric_only=True).to_dict()\n",
        "        elif params.operation == \"count\":\n",
        "            result = filtered_df[params.columns].count().to_dict()\n",
        "        else:\n",
        "            return f\"Unsupported operation: {params.operation}\", {}\n",
        "\n",
        "        return \"Query successful.\", {\"result\": result}\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", {}\n",
        "\n",
        "('properties', 'index', 'anyOf', '2')\n",
        "\n",
        "\n",
        "@tool(name_or_callable=\"GetData\", response_format=\"content_and_artifact\")\n",
        "def get_data(\n",
        "params: GetDataParams, df_id: str = \"\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "Retrieves data from a DataFrame by ID, for flexible row/column selection and retrieval specific cells.\n",
        "Args:\n",
        "  params: A GetDataParams object defining the query.\n",
        "  df_id: The ID of the DataFrame in the global registry. Can be skipped since it is provided in the params.\n",
        "Returns:\n",
        "  A formatted string of the retrieved data with column names and values.\n",
        "\n",
        "Example Usage:\n",
        "# Get the 3rd row and columns 'Name' and 'Age'\n",
        "get_data(GetDataParams(df_id='my_df', index=2, columns=['Name', 'Age'])\n",
        "\n",
        "# Get rows with indices 1, 3, and 5, and all columns\n",
        "get_data(GetDataParams(df_id='my_df', index=[1, 3, 5]))\n",
        "\n",
        "# Get rows with indices from 10 to 20, and columns 'City' and 'Country'\n",
        "get_data(GetDataParams(df_id='my_df', index=(10, 20), columns=['City', 'Country'])\n",
        "\n",
        "# Get specific cell values\n",
        "get_data(df_id='my_df', cells=[(1,'Name'),(5,'Age'),(10,'City')])\n",
        "    \"\"\"\n",
        "    if df_id is None or df_id == \"\":\n",
        "      df_id = params.df_id\n",
        "    elif df_id.strip() != params.df_id.strip():\n",
        "      return \"Error: df_id mismatch.\"\n",
        "    index = params.index\n",
        "    columns = params.columns\n",
        "    cells = params.cells\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "            return f\"Error loading DataFrame: {e}\"\n",
        "        pass\n",
        "\n",
        "    if cells is not None:\n",
        "        # Retrieve specific cell values\n",
        "        output_str = \"\"\n",
        "        for row_index, col_name in cells:\n",
        "            val = df.loc[row_index, col_name]\n",
        "            output_str += f\"Value at ({row_index}, {col_name}): {val}\\n\"\n",
        "        return output_str\n",
        "\n",
        "    if isinstance(index, int):\n",
        "        rows = df.loc[[index]]  # Single row\n",
        "    elif isinstance(index, list):\n",
        "        rows = df.loc[index]  # List of rows\n",
        "    elif isinstance(index, tuple):\n",
        "        rows = df.loc[index:index]  # Range of rows\n",
        "    else:\n",
        "        return \"Error: Invalid index format.\"\n",
        "\n",
        "    if columns == \"all\":\n",
        "        columns_to_include = df.columns\n",
        "    elif isinstance(columns, str):\n",
        "        columns_to_include = [columns]\n",
        "    elif isinstance(columns, list):\n",
        "        columns_to_include = columns\n",
        "    else:\n",
        "        return \"Error: Invalid columns format.\"\n",
        "\n",
        "    selected_data = rows[columns_to_include]\n",
        "\n",
        "    # Format the output string\n",
        "    output_str = \"\"\n",
        "    for row_index, row_data in selected_data.iterrows():\n",
        "        output_str += f\"Row {row_index}:\\n\"\n",
        "        for col, val in row_data.items():\n",
        "            output_str += f\"  {col}: {val}\\n\"\n",
        "    return output_str\n",
        "\n",
        "@tool(\"GetDescriptiveStatistics\")\n",
        "def get_descriptive_statistics(df_id: str, column_names: str = \"all\") -> str:\n",
        "    \"\"\"\n",
        "    Input should be 'df_id' and optionally 'column_names' (comma-separated string).\n",
        "    If 'column_names' is 'all' or not provided, statistics for all columns are returned.\n",
        "\n",
        "    Calculates descriptive statistics for specified columns in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_names: A comma-separated string of column names to analyze.\n",
        "                      Defaults to \"all\", which analyzes all columns.\n",
        "\n",
        "    Returns:\n",
        "        A string representation of the descriptive statistics table.\n",
        "\n",
        "    Example:\n",
        "        get_descriptive_statistics(df_id='my_df', column_names='Age, Income')\n",
        "        would return descriptive statistics for the 'Age' and 'Income' columns.\n",
        "\n",
        "    \"\"\"\n",
        "    pprint(f\"Getting descriptive statistics for {column_names} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "        pass\n",
        "      columns_to_describe = df.columns if column_names.lower() == 'all' or not column_names else column_names.split(',')\n",
        "      desc_stats = df[columns_to_describe].describe()\n",
        "      return desc_stats.to_string()\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating descriptive statistics: {e}\"\n",
        "\n",
        "@tool(\"CalculateCorrelation\")\n",
        "def calculate_correlation(df_id: str, column1_name: str, column2_name: str) -> str:\n",
        "    \"\"\"Useful to calculate the Pearson correlation coefficient between two columns in a DataFrame.\n",
        "    Input should be 'df_id', 'column1_name', and 'column2_name'.\n",
        "\n",
        "    Calculates the Pearson correlation coefficient between two columns.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column1_name: The name of the first column.\n",
        "        column2_name: The name of the second column.\n",
        "\n",
        "    Returns:\n",
        "        A string representation of the correlation coefficient.\n",
        "\n",
        "    Example:\n",
        "        calculate_correlation(df_id='my_df', column1_name='Age', column2_name='Income')\n",
        "        would return the correlation between 'Age' and 'Income'.\n",
        "\n",
        "    \"\"\"\n",
        "    pprint(f\"Calculating correlation between {column1_name} and {column2_name} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "        pass\n",
        "      correlation = df[column1_name].corr(df[column2_name])\n",
        "      return f\"Correlation between '{column1_name}' and '{column2_name}': {correlation}\"\n",
        "    except Exception as e:\n",
        "      return f\"Error calculating correlation: {e}\"\n",
        "\n",
        "@tool(\"PerformHypothesisTest\")\n",
        "def perform_hypothesis_test(df_id: str, column_name: str, value: float) -> str:\n",
        "    \"\"\"Useful to perform a one-sample t-test to check if the mean of a column is significantly different from a given value.\n",
        "    Input should be 'df_id', 'column_name', and 'value' to test against.\n",
        "\n",
        "    Performs a one-sample t-test to check if the mean of a column is significantly different from a given value.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the column to test.\n",
        "        value: The value to compare the mean against.\n",
        "\n",
        "    Returns:\n",
        "        A string describing the t-test results, including the t-statistic, p-value, and whether the null hypothesis is rejected.\n",
        "\n",
        "    Example:\n",
        "        perform_hypothesis_test(df_id='my_df', column_name='Age', value=30)\n",
        "        would test if the average 'Age' is significantly different from 30.\n",
        "    \"\"\"\n",
        "    pprint(f\"Performing hypothesis test on {column_name} with value {value} from {df_id}\")\n",
        "\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "        pass\n",
        "        column_data = df[column_name].dropna() # Handle NaNs for t-test\n",
        "        if not pd.api.types.is_numeric_dtype(column_data):\n",
        "            return \"Error: Hypothesis test can only be performed on numeric columns.\"\n",
        "\n",
        "        t_statistic, p_value = stats.ttest_1samp(a=column_data, popmean=value)\n",
        "        alpha = 0.05  # Significance level\n",
        "        if p_value < alpha:\n",
        "            result = f\"Reject null hypothesis. Mean is significantly different from {value}. \"\n",
        "        else:\n",
        "            result = f\"Fail to reject null hypothesis. Mean is not significantly different from {value}. \"\n",
        "        return result + f\"T-statistic: {t_statistic}, P-value: {p_value}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error performing hypothesis test: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "analyst_tools = [get_dataframe_schema,get_descriptive_statistics, calculate_correlation, perform_hypothesis_test, get_column_names, get_data,query_dataframe]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ1tuCJZdkXk"
      },
      "outputs": [],
      "source": [
        "_TEMP_DIRECTORY = TemporaryDirectory()\n",
        "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
        "\n",
        "from typing import Annotated, List, Optional\n",
        "@tool\n",
        "def create_sample(\n",
        "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
        "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
        ") -> Annotated[str, \"Path of the saved file of sample data from the dataset.\"]:\n",
        "    \"\"\"Create and save an outline.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        for i, point in enumerate(points):\n",
        "            file.write(f\"{i + 1}. {point}\\n\")\n",
        "    return f\"sample data saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def read_file(\n",
        "    file_name: Annotated[str, \"File path to read the file from.\"],\n",
        "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
        "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
        ") -> str:\n",
        "    \"\"\"Read the specified data file.\"\"\"\n",
        "    pprint(f\"Reading file {file_name} from {WORKING_DIRECTORY} \\n with start {start} and end {end}\")\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    if start is None:\n",
        "        start = 0\n",
        "    if end is None:\n",
        "        end = start + 10\n",
        "    # if lines:\n",
        "    #   pprint(f\"Content read: /n {lines[start:end]} /n\")\n",
        "    return \"\\n\".join(lines[start:end])\n",
        "\n",
        "\n",
        "@tool\n",
        "def write_file(\n",
        "    content: Annotated[str, \"Text content to be written into the file.\"],\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
        "    \"\"\"Create and save a data file of any format.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(content)\n",
        "    return f\"Document saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def edit_file(\n",
        "    file_name: Annotated[str, \"Path of the file to be edited.\"],\n",
        "    inserts: Annotated[\n",
        "        Dict[int, str],\n",
        "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
        "    ],\n",
        ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
        "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sorted_inserts = sorted(inserts.items())\n",
        "\n",
        "    for line_number, text in sorted_inserts:\n",
        "        if 1 <= line_number <= len(lines) + 1:\n",
        "            lines.insert(line_number - 1, text + \"\\n\")\n",
        "        else:\n",
        "            return f\"Error: Line number {line_number} is out of range.\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "    return f\"Document edited and saved to {file_name}\"\n",
        "\n",
        "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
        "\n",
        "repl = PythonREPL()\n",
        "\n",
        "@tool\n",
        "def python_repl_tool(\n",
        "    code: Annotated[str, \"The python code to execute.\"],\n",
        "    df_id: Annotated[str, \"The ID of the DataFrame in the global registry.\"]\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Executes Python code within a REPL environment that has access to the global DataFrame registry.\n",
        "\n",
        "    This tool allows you to execute custom Python code for more complex data analysis tasks.\n",
        "    You can access the DataFrame using the provided `df_id` and the `get_df_from_registry` helper function.\n",
        "\n",
        "    Args:\n",
        "        code: The Python code to execute.\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "\n",
        "    Returns:\n",
        "        The output of the executed Python code.\n",
        "\n",
        "    Example:\n",
        "        To calculate the mean of the 'Age' column in the DataFrame with ID 'my_df', you would use the following code:\n",
        "\n",
        "        ```python\n",
        "        df = get_df_from_registry('my_df')\n",
        "        mean_age = df['Age'].mean()\n",
        "        print(f\"The mean age is: {mean_age}\")\n",
        "        ```\n",
        "    \"\"\"\n",
        "    # Define the helper function inside the tool\n",
        "    def get_df_from_registry(df_id):\n",
        "        \"\"\"Retrieves a DataFrame from the global registry.\"\"\"\n",
        "        #... implementation to access the registry...\n",
        "        # Example using the DataFrameRegistry class:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        return df\n",
        "\n",
        "    # Now, the 'get_df_from_registry' function is available within the Python REPL environment\n",
        "    try:\n",
        "        # Execute the provided code, which can now use the helper function\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    return result\n",
        "\n",
        "analyst_tools.append(python_repl_tool)\n",
        "# analyst_tools.append(read_file)\n",
        "analyst_tools.append(create_sample)\n",
        "data_cleaning_tools.append(Tool(name=\"WriteFile\",func = write_file,description=\"Useful to create and save a data file of any format.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"PythonREPL\",func = python_repl_tool,description=\"Useful to execute python code. If you want to see the output of a value, you should print it out with `print(...)`. This is visible to the user.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"EditFile\",func = edit_file,description=\"Useful to edit a document by inserting text at specific line numbers.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"QueryDataframe\", func = query_dataframe,description=\"Useful to query a dataframe.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"GetData\",func = get_data,description=\"Useful to retrieve data from the DataFrame with the specified ID, supporting flexible row and column selection, and specific cell retrieval.\"))\n",
        "\n",
        "file_writer_tools = [get_dataframe_schema,write_file, edit_file, read_file, python_repl_tool]\n",
        "visualization_tools = [python_repl_tool,get_dataframe_schema,get_data,get_column_names]\n",
        "report_generator_tools = [\n",
        "    python_repl_tool,\n",
        "    write_file,\n",
        "    edit_file,\n",
        "    read_file,\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBguFhuoZV5G"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional, Literal\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import HumanMessage, trim_messages, AIMessage, SystemMessage, ToolMessage, ToolMessageChunk, ToolCall\n",
        "from langchain_openai import ChatOpenAI # Or your preferred LLM\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "import pandas as pd\n",
        "import io\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langchain_core.stores import BaseStore\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        ")\n",
        "in_memory_store = InMemoryStore()\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=oai_key)\n",
        "\n",
        "#input_variables=['dataset_description', 'data_sample', 'tool_descriptions', 'output_format'],\n",
        "\n",
        "def create_data_cleaner_agent(initial_description:str, df_ids:List[str] = []) -> BaseChatModel:\n",
        "  checkpointer = MemorySaver()\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in data_cleaning_tools])\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      SystemMessage(content=data_cleaner_prompt_template.format(tool_descriptions=tool_descriptions, output_format=CleaningMetadata.model_json_schema(), dataset_description=initial_description, data_sample=None, available_df_ids=df_ids)),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "  ])\n",
        "\n",
        "  return create_react_agent(llm, tools=[*data_cleaning_tools], state_schema=State, checkpointer=checkpointer,store = in_memory_store,response_format= CleaningMetadata,prompt=prompt, name= \"data_cleaner\", version=\"v2\")\n",
        "\n",
        "\n",
        "def create_initial_analysis_agent(user_prompt:str, df_ids:List[str] = []) -> BaseChatModel:\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      SystemMessage(content=analyst_prompt_template_initial.format(tool_descriptions=tool_descriptions, output_format=InitialDescription.model_json_schema(), user_prompt=user_prompt, available_df_ids=df_ids)),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "  ])\n",
        "\n",
        "  checkpointer = MemorySaver()\n",
        "  return create_react_agent(llm, tools=analyst_tools, state_schema=State,checkpointer=checkpointer, store = in_memory_store,response_format= InitialDescription,prompt=prompt, name= \"initial_analysis\", version=\"v2\")\n",
        "\n",
        "#input_variables=['cleaned_dataset_description', 'cleaning_metadata', 'tool_descriptions', 'output_format'],\n",
        "\n",
        "\n",
        "def create_analyst_agent(initial_description:str, df_ids:List[str] = []) -> BaseChatModel:\n",
        "  checkpointer = MemorySaver()\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      SystemMessage(content=analyst_prompt_template_main.format(tool_descriptions=tool_descriptions, output_format=AnalysisInsights.model_json_schema(), cleaned_dataset_description=initial_description, cleaning_metadata=None, available_df_ids=df_ids)),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "  ])\n",
        "  return create_react_agent(llm, tools=analyst_tools, state_schema=State, response_format= AnalysisInsights,checkpointer=checkpointer,store = in_memory_store,prompt=prompt, name= \"analyst\", version=\"v2\")\n",
        "\n",
        "def create_file_writer_agent() -> BaseChatModel:\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in file_writer_tools])\n",
        "\n",
        "  return create_react_agent(llm, tools=file_writer_tools, state_schema=State, checkpointer=MemorySaver(),store = in_memory_store)\n",
        "\n",
        "\n",
        "def create_visualization_agent(df_ids:List[str] = []) -> BaseChatModel:\n",
        "    tool_descriptions = \"\\n\".join(\n",
        "        [f\"{tool.name}: {tool.description}\" for tool in visualization_tools]\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            SystemMessage(\n",
        "                content=visualization_prompt_template.format(\n",
        "                    tool_descriptions=tool_descriptions,\n",
        "                    output_format=VisualizationResults.model_json_schema(),\n",
        "                    cleaned_dataset_description=\"\",\n",
        "                    analysis_insights=\"\",\n",
        "                    available_df_ids=df_ids,\n",
        "\n",
        "                )\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpointer = MemorySaver()\n",
        "    return create_react_agent(\n",
        "        llm,\n",
        "        tools=[*visualization_tools],\n",
        "        state_schema=State,\n",
        "        checkpointer=checkpointer,\n",
        "        store=in_memory_store,\n",
        "        response_format=VisualizationResults,\n",
        "        prompt=prompt,\n",
        "        name=\"visualization\",\n",
        "        version=\"v2\",\n",
        "    )\n",
        "\n",
        "def create_report_generator_agent(df_ids:List[str] = []) -> BaseChatModel:\n",
        "    tool_descriptions = \"\\n\".join(\n",
        "        [f\"{tool.name}: {tool.description}\" for tool in report_generator_tools]\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            SystemMessage(\n",
        "                content=report_generator_prompt_template.format(\n",
        "                    tool_descriptions=tool_descriptions,\n",
        "                    output_format=ReportResults.model_json_schema(),\n",
        "                    cleaning_metadata=\"\",\n",
        "                    analysis_insights=\"\",\n",
        "                    visualization_results=\"\",\n",
        "                    available_df_ids=df_ids,\n",
        "                )\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpointer = MemorySaver()\n",
        "    return create_react_agent(\n",
        "        llm,\n",
        "        tools=[*report_generator_tools],\n",
        "        state_schema=State,\n",
        "        checkpointer=checkpointer,\n",
        "        store=in_memory_store,\n",
        "        response_format=ReportResults,\n",
        "        prompt=prompt,\n",
        "        name=\"report_generator\",\n",
        "        version=\"v2\",\n",
        "    )\n",
        "\n",
        "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
        "\n",
        "    # Get the user id from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Namespace the memory\n",
        "    namespace = (user_id, \"memories\")\n",
        "\n",
        "    # ... Analyze conversation and create a new memory\n",
        "\n",
        "    # Create a new memory ID\n",
        "    memory_id = str(uuid.uuid4())\n",
        "\n",
        "    # We create a new memory\n",
        "    store.put(namespace, memory_id, {\"memory\": state[\"messages\"][-1].content})\n",
        "\n",
        "\n",
        "def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n",
        "    options = [\"FINISH\"] + members\n",
        "    system_prompt = (\n",
        "        \"You are a supervisor tasked with managing a conversation between the\"\n",
        "        f\" following workers: {members}. Given the following user request,\"\n",
        "        \" respond with the worker to act next. Each worker will perform a\"\n",
        "        \" task and respond with their results and status. When finished,\"\n",
        "        \" respond with FINISH.\"\n",
        "    )\n",
        "    class Router(TypedDict):\n",
        "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
        "\n",
        "        next: Literal[*options]\n",
        "\n",
        "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
        "        \"\"\"An LLM-based router.\"\"\"\n",
        "        _count_ = state.get(\"_count_\", 0)\n",
        "        count_ = _count_ + 1\n",
        "        state[\"_count_\"] = count_\n",
        "        completed_ = None\n",
        "        # list_complete = []\n",
        "        agent_bool_map = {\n",
        "            \"initial_analysis\": state.get(\"initial_analysis_complete\", False),\n",
        "            \"data_cleaner\": state.get(\"data_cleaning_complete\", False),\n",
        "            \"analyst\": state.get(\"analyst_complete\", False),\n",
        "            \"file_writer\": state.get(\"file_writer_complete\", False),\n",
        "            \"visualization\": state.get(\"visualization_complete\", False),\n",
        "            \"report_generator\": state.get(\"report_generator_complete\", False),\n",
        "        }\n",
        "\n",
        "        # for ag in agent_bool_map:\n",
        "        #   if agent_bool_map[ag]:\n",
        "        #     list_complete.append(ag)\n",
        "\n",
        "        for comp_ag, comp_val in agent_bool_map.items():\n",
        "          if comp_val:\n",
        "            completed_ = f\"{system_prompt}. /n {comp_ag} is complete, so dont pass to {comp_ag} again.\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt if not completed_ else completed_},\n",
        "        ] + state[\"messages\"]\n",
        "        response = llm.with_structured_output(Router).invoke(messages, state[\"_config\"])\n",
        "        goto = response[\"next\"]\n",
        "        if goto == \"FINISH\":\n",
        "            goto = END\n",
        "\n",
        "        print(f\"Coordinator node: current state keys: {state.keys()}. Current count: {count_}\")\n",
        "        update_dict = {\"next\": goto}\n",
        "        if \"user_prompt\" in state:\n",
        "            update_dict[\"user_prompt\"] = state[\"user_prompt\"]\n",
        "        if \"messages\" in state:\n",
        "            update_dict[\"messages\"] = state[\"messages\"]\n",
        "        if \"initial_description\" in state:\n",
        "            update_dict[\"initial_description\"] = state[\"initial_description\"]\n",
        "        if \"cleaning_metadata\" in state:\n",
        "            update_dict[\"cleaning_metadata\"] = state[\"cleaning_metadata\"]\n",
        "        if \"analysis_insights\" in state:\n",
        "            update_dict[\"analysis_insights\"] = state[\"analysis_insights\"]\n",
        "        if \"config\" in state:\n",
        "            update_dict[\"config\"] = state[\"config\"]\n",
        "        if \"file_writer_complete\" in state:\n",
        "            update_dict[\"file_writer_complete\"] = state[\"file_writer_complete\"]\n",
        "        if \"analyst_complete\" in state:\n",
        "            update_dict[\"analyst_complete\"] = state[\"analyst_complete\"]\n",
        "        if \"data_cleaning_complete\" in state:\n",
        "            update_dict[\"data_cleaning_complete\"] = state[\"data_cleaning_complete\"]\n",
        "\n",
        "        if \"initial_analysis_complete\" in state:\n",
        "            update_dict[\"initial_analysis_complete\"] = state[\"initial_analysis_complete\"]\n",
        "        if \"visualization_complete\" in state:\n",
        "            update_dict[\"visualization_complete\"] = state[\"visualization_complete\"]\n",
        "        if \"report_generator_complete\" in state:\n",
        "            update_dict[\"report_generator_complete\"] = state[\"report_generator_complete\"]\n",
        "        print(f\"/n Coordinator node: update_dict: {update_dict} and goto: {goto} /n\") # Debugging\n",
        "        update_memory(state, state[\"_config\"], store=in_memory_store)\n",
        "\n",
        "        return Command(goto=goto, update=update_dict)\n",
        "\n",
        "    return supervisor_node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oSLpBrTN3FIy",
        "outputId": "a78597f7-7f5f-4d7b-be49-a22bce21abd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/datafiniti/consumer-reviews-of-amazon-products/versions/5\n",
            "'/root/.cache/kagglehub/datasets/datafiniti/consumer-reviews-of-amazon-products/versions/5/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv'\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'global_df_registry' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9cb79049fd65>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdf_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_df_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0msample_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Please analyze the dataset named {df_name} You have tools available to you for accessing the data using the following str as the df_id parameter: `{df_id}`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'global_df_registry' is not defined"
          ]
        }
      ],
      "source": [
        "# Download sample dataset from Kagglehub\n",
        "from pprint import pprint\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"datafiniti/consumer-reviews-of-amazon-products\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "raw_path = os.path.join(path, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
        "pprint(raw_path)\n",
        "\n",
        "ext = os.path.splitext(raw_path)[-1].lower()\n",
        "try:\n",
        "    ext = os.path.splitext(raw_path)[-1].lower()\n",
        "    if ext == \".csv\":\n",
        "        df = pd.read_csv(raw_path)\n",
        "    elif ext == \".json\":\n",
        "        df = pd.read_json(raw_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please use CSV or JSON.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading file: {e}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "\n",
        "# Sample Prompt for use with sample dataset - will be replaced with a user interface\n",
        "\n",
        "df_name = \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products\"\n",
        "\n",
        "df_id = global_df_registry.register_dataframe(df, df_name, raw_path)\n",
        "sample_prompt = (\"user\", f\"Please analyze the dataset named {df_name} You have tools available to you for accessing the data using the following str as the df_id parameter: `{df_id}`.\")\n",
        "pprint(sample_prompt)\n",
        "\n",
        "data_cleaner_agent = create_data_cleaner_agent(initial_description=sample_prompt[1], df_ids=[df_id])\n",
        "initial_analysis_agent = create_initial_analysis_agent(user_prompt=sample_prompt[1], df_ids=[df_id])\n",
        "analyst_agent = create_analyst_agent(initial_description=sample_prompt[1], df_ids=[df_id])\n",
        "file_writer_agent = create_file_writer_agent()\n",
        "visualization_agent = create_visualization_agent(df_ids=[df_id])\n",
        "report_generator_agent = create_report_generator_agent(df_ids=[df_id])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixJqmfH0lBfE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, trim_messages, AIMessage, SystemMessage, ToolMessage, ToolMessageChunk, ToolCall\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Define a node function that uses a ChatPromptTemplate and returns a Command.\n",
        "# ['dataset_text_description', 'tool_descriptions', 'output_format'],\n",
        "def initial_analysis_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "    # Get output format\n",
        "    output_format = InitialDescription.model_json_schema()\n",
        "\n",
        "\n",
        "    # pprint(f\"State in initial analysis node: {state}\")\n",
        "    msgs = trim_messages(state[\"messages\"],max_tokens=50,token_counter=len)\n",
        "    #remove the first message (as long as its a system message) and replace it with the updated one\n",
        "    if isinstance(msgs[0], SystemMessage):\n",
        "      msgs.pop(0)\n",
        "    else:\n",
        "      #find the system message if it exists\n",
        "      sm_index = next((i for i, msg in enumerate(msgs) if isinstance(msg, SystemMessage)), None)\n",
        "\n",
        "      if sm_index is not None:\n",
        "        msgs.pop(sm_index)\n",
        "\n",
        "\n",
        "    # pprint(f\"Messages in initial analysis node: {msgs}\")\n",
        "    msgs.insert(0, SystemMessage(analyst_prompt_template_initial.format(tool_descriptions=tool_descriptions, output_format=output_format, user_prompt=state[\"user_prompt\"], available_df_ids=state[\"df_ids\"])))\n",
        "    namespace = (state[\"_config\"][\"configurable\"][\"user_id\"], \"memories\")\n",
        "        # Search based on the most recent message\n",
        "    memories = in_memory_store.search(\n",
        "        namespace,\n",
        "        query=state[\"messages\"][-1].content,\n",
        "        limit=3\n",
        "    )\n",
        "\n",
        "    info = \"\\n\".join([d.value[\"memory\"] for d in memories])\n",
        "    result = initial_analysis_agent.invoke({\"messages\":msgs},subgraphs=False, debug=False)\n",
        "    print(f\"Initial analysis result: {result}\")\n",
        "\n",
        "    update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"initial_analysis\")],\"initial_description\": result[\"structured_response\"], \"initial_analysis_complete\": True}\n",
        "    return Command(update=update, goto=\"supervisor\", )\n",
        "\n",
        "\n",
        "def data_cleaner_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in data_cleaning_tools])\n",
        "  # Get output format\n",
        "  output_format = CleaningMetadata.model_json_schema()\n",
        "  msgs = trim_messages(state[\"messages\"],max_tokens=50,token_counter=len)\n",
        "  #remove the first message (as long as its a system message) and replace it with the updated one\n",
        "  if isinstance(msgs[0], SystemMessage):\n",
        "    msgs.pop(0)\n",
        "  else:\n",
        "    #find the system message if it exists\n",
        "    sm_index = next((i for i, msg in enumerate(msgs) if isinstance(msg, SystemMessage)), None)\n",
        "\n",
        "    if sm_index is not None:\n",
        "      msgs.pop(sm_index)\n",
        "\n",
        "  msgs.insert(0, SystemMessage(data_cleaner_prompt_template.format(tool_descriptions=tool_descriptions, output_format=output_format, dataset_description=state[\"initial_description\"].dataset_description, data_sample=state[\"initial_description\"].data_sample, available_df_ids=state[\"df_ids\"])))\n",
        "  namespace = (state[\"_config\"][\"configurable\"][\"user_id\"], \"memories\")\n",
        "  # Search based on the most recent message\n",
        "  memories = in_memory_store.search(\n",
        "        namespace,\n",
        "        query=state[\"messages\"][-1].content,\n",
        "        limit=3\n",
        "    )\n",
        "\n",
        "\n",
        "  # state[\"messages\"].insert(0, (\"system\",data_cleaner_prompt_template.format(**input_vars)))\n",
        "  result = data_cleaner_agent.invoke({\"messages\":msgs})\n",
        "  pprint(result)\n",
        "  update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"data_cleaner\")],\"cleaning_metadata\": result[\"structured_response\"], \"data_cleaning_complete\": True}\n",
        "  return Command(update=update, goto=\"supervisor\", )\n",
        "\n",
        "\n",
        "\n",
        "def analyst_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    # Create a ChatPromptTemplate with placeholders for variables.\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "    # Get output format\n",
        "    output_format = AnalysisInsights.model_json_schema()\n",
        "\n",
        "    namespace = (state[\"_config\"][\"configurable\"][\"user_id\"], \"memories\")\n",
        "        # Search based on the most recent message\n",
        "    memories = in_memory_store.search(\n",
        "        namespace,\n",
        "        query=state[\"messages\"][-1].content,\n",
        "        limit=3\n",
        "    )\n",
        "\n",
        "    msgs = trim_messages(state[\"messages\"],max_tokens=50,token_counter=len)\n",
        "    #remove the first message (as long as its a system message) and replace it with the updated one\n",
        "    if isinstance(msgs[0], SystemMessage):\n",
        "      msgs.pop(0)\n",
        "    else:\n",
        "      #find the system message if it exists\n",
        "      sm_index = next((i for i, msg in enumerate(msgs) if isinstance(msg, SystemMessage)), None)\n",
        "\n",
        "      if sm_index is not None:\n",
        "        msgs.pop(sm_index)\n",
        "\n",
        "    msgs.insert(0, SystemMessage(analyst_prompt_template_main.format(tool_descriptions=tool_descriptions, output_format=output_format, cleaned_dataset_description=state[\"cleaning_metadata\"].data_description_after_cleaning, cleaning_metadata=state[\"cleaning_metadata\"], available_df_ids=state[\"df_ids\"])))\n",
        "    result = analyst_agent.invoke({\"messages\":msgs})\n",
        "    pprint(f\"Analyst result summary: {result['structured_response'].summary}\")\n",
        "    pprint(f\"Analyst result correlation_insights: {result['structured_response'].correlation_insights}\")\n",
        "    pprint(f\"Analyst result anomaly_insights: {result['structured_response'].anomaly_insights}\")\n",
        "    pprint(f\"Analyst result recommended_visualizations: {result['structured_response'].recommended_visualizations}\")\n",
        "\n",
        "    update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"analyst\")],\"analysis_insights\": result[\"structured_response\"], \"analyst_complete\": True}\n",
        "    return Command(update=update, goto=\"supervisor\", )\n",
        "\n",
        "def file_writer_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in file_writer_tools])\n",
        "\n",
        "\n",
        "    result = file_writer_agent.invoke(state)\n",
        "    pprint(f\"File writer result: {result}\")\n",
        "    return Command(update={\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"file_writer\")]}, goto=\"supervisor\", )\n",
        "\n",
        "def visualization_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in visualization_tools])\n",
        "    # Get output format\n",
        "    output_format = VisualizationResults.model_json_schema()\n",
        "\n",
        "    msgs = trim_messages(state[\"messages\"], max_tokens=50, token_counter=len)\n",
        "    # remove the first message (as long as its a system message) and replace it with the updated one\n",
        "    if isinstance(msgs, SystemMessage):\n",
        "        msgs.pop(0)\n",
        "    else:\n",
        "        # find the system message if it exists\n",
        "        sm_index = next((i for i, msg in enumerate(msgs) if isinstance(msg, SystemMessage)), None)\n",
        "\n",
        "        if sm_index is not None:\n",
        "            msgs.pop(sm_index)\n",
        "\n",
        "    msgs.insert(\n",
        "        0,\n",
        "        SystemMessage(\n",
        "            visualization_prompt_template.format(\n",
        "                tool_descriptions=tool_descriptions,\n",
        "                output_format=output_format,\n",
        "                cleaned_dataset_description=state[\"cleaning_metadata\"].data_description_after_cleaning,\n",
        "                analysis_insights=state[\"analysis_insights\"],\n",
        "                available_df_ids=state[\"df_ids\"]\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    result = visualization_agent.invoke({\"messages\": msgs})\n",
        "    pprint(f\"Visualization result: {result}\")\n",
        "\n",
        "    update = {\n",
        "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"visualization\")],\n",
        "        \"visualization_results\": result[\"structured_response\"],\n",
        "        \"visualization_complete\": True,\n",
        "    }\n",
        "    return Command(update=update, goto=\"supervisor\")\n",
        "\n",
        "\n",
        "def report_generator_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in report_generator_tools])\n",
        "    # Get output format\n",
        "    output_format = ReportResults.model_json_schema()\n",
        "\n",
        "    msgs = trim_messages(state[\"messages\"], max_tokens=50, token_counter=len)\n",
        "    # remove the first message (as long as its a system message) and replace it with the updated one\n",
        "    if isinstance(msgs, SystemMessage):\n",
        "        msgs.pop(0)\n",
        "    else:\n",
        "        # find the system message if it exists\n",
        "        sm_index = next((i for i, msg in enumerate(msgs) if isinstance(msg, SystemMessage)), None)\n",
        "\n",
        "        if sm_index is not None:\n",
        "            msgs.pop(sm_index)\n",
        "\n",
        "    msgs.insert(\n",
        "        0,\n",
        "        SystemMessage(\n",
        "            report_generator_prompt_template.format(\n",
        "                tool_descriptions=tool_descriptions,\n",
        "                output_format=output_format,\n",
        "                cleaning_metadata=state[\"cleaning_metadata\"],\n",
        "                analysis_insights=state[\"analysis_insights\"],\n",
        "                visualization_results=state[\"visualization_results\"],\n",
        "                available_df_ids=state[\"df_ids\"]\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    result = report_generator_agent.invoke({\"messages\": msgs})\n",
        "    pprint(f\"Report generator result: {result}\")\n",
        "\n",
        "    update = {\n",
        "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"report_generator\")],\n",
        "        \"report_results\": result[\"structured_response\"],\n",
        "        \"report_generator_complete\": True,\n",
        "    }\n",
        "    return Command(update=update, goto=\"supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v52mP2CxPj4"
      },
      "outputs": [],
      "source": [
        "\n",
        "coordinator_node = make_supervisor_node(llm, [\"initial_analysis\", \"data_cleaner\", \"analyst\", \"file_writer\", \"visualization\", \"report_generator\"])\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\",\"user_id\": \"user-1\"},\"recursion_limit\": 150}\n",
        "\n",
        "data_analysis_team_builder = StateGraph(State)\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "data_analysis_team_builder.add_node(\"supervisor\", coordinator_node)\n",
        "data_analysis_team_builder.add_node(\"initial_analysis\", initial_analysis_node)\n",
        "data_analysis_team_builder.add_node(\"data_cleaner\", data_cleaner_node)\n",
        "data_analysis_team_builder.add_node(\"analyst\", analyst_node)\n",
        "data_analysis_team_builder.add_node(\"file_writer\", file_writer_node)\n",
        "data_analysis_team_builder.add_node(\"visualization\", visualization_node)\n",
        "data_analysis_team_builder.add_node(\"report_generator\", report_generator_node)\n",
        "data_analysis_team_builder.add_edge(START, \"supervisor\")\n",
        "\n",
        "data_detective_graph = data_analysis_team_builder.compile(checkpointer=checkpointer,store = in_memory_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D0coE-3QW11"
      },
      "outputs": [],
      "source": [
        "# async for event in data_detective_graph.astream_events(\n",
        "#     {\"messages\": [sample_prompt], \"user_prompt\":sample_prompt[1],\"_config\":config},config,stream_mode=\"debug\",subgraphs=True, debug=True, version=\"v2\"):\n",
        "#     kind = event[\"event\"]\n",
        "#     if kind == \"on_chain_start\":\n",
        "#         if (\n",
        "#             event[\"name\"] == \"Agent\"\n",
        "#         ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "#             print(\n",
        "#                 f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
        "#             )\n",
        "#     elif kind == \"on_chain_end\":\n",
        "#         if (\n",
        "#             event[\"name\"] == \"Agent\"\n",
        "#         ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "#             print()\n",
        "#             print(\"--\")\n",
        "#             print(\n",
        "#                 f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
        "#             )\n",
        "#     if kind == \"on_chat_model_stream\":\n",
        "#         content = event[\"data\"][\"chunk\"].content\n",
        "#         if content:\n",
        "#             # Empty content in the context of OpenAI means\n",
        "#             # that the model is asking for a tool to be invoked.\n",
        "#             # So we only print non-empty content\n",
        "#             print(content, end=\"|\")\n",
        "#     elif kind == \"on_tool_start\":\n",
        "#         print(\"--\")\n",
        "#         print(\n",
        "#             f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
        "#         )\n",
        "#     elif kind == \"on_tool_end\":\n",
        "#         print(f\"Done tool: {event['name']}\")\n",
        "#         print(f\"Tool output was: {event['data'].get('output')}\")\n",
        "#         print(\"--\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "WFTXS7s3x4Y3",
        "outputId": "5d6c5dc7-1c92-46d0-ab70-f733fe327eff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(data_detective_graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mvg52ebjIn0_",
        "outputId": "c76c1244-36ef-4051-c86b-9e758d9fea4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coordinator node: current state keys: dict_keys(['messages', 'user_prompt', 'df_ids', '_config', 'is_last_step', 'remaining_steps', '_count_']). Current count: 1\n",
            "/n Coordinator node: update_dict: {'next': 'initial_analysis', 'user_prompt': 'Please analyze the dataset named Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products You have tools available to you for accessing the data using the following str as the df_id parameter: `Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products`.', 'messages': [HumanMessage(content='Please analyze the dataset named Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products You have tools available to you for accessing the data using the following str as the df_id parameter: `Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products`.', additional_kwargs={}, response_metadata={}, name='user', id='0ba1db10-9b09-4b2c-b3e5-ca3697896ff4')]} and goto: initial_analysis /n\n",
            "((),\n",
            " {'supervisor': {'messages': [HumanMessage(content='Please analyze the dataset named Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products You have tools available to you for accessing the data using the following str as the df_id parameter: `Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products`.', additional_kwargs={}, response_metadata={}, name='user', id='0ba1db10-9b09-4b2c-b3e5-ca3697896ff4')],\n",
            "                 'next': 'initial_analysis',\n",
            "                 'user_prompt': 'Please analyze the dataset named '\n",
            "                                'Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products '\n",
            "                                'You have tools available to you for accessing '\n",
            "                                'the data using the following str as the df_id '\n",
            "                                'parameter: '\n",
            "                                '`Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products`.'}})\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"Invalid schema for function 'GetData': [{'type': 'integer'}, {'type': 'string'}] is not of type 'object', 'boolean'.\", 'type': 'invalid_request_error', 'param': 'tools[5].function.parameters', 'code': 'invalid_function_parameters'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ea0e086e0a4f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_detective_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_prompt_final\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user_prompt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_prompt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"_config\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"df_ids\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"updates\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubgraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;31m# pprint(f\"State: {s}/n/n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1777\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1780\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# panic on failure or timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         _panic_or_proceed(\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpanic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36m_panic_or_proceed\u001b[0;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# raise the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpanic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minflight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# if we got here means we timed out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/executor.py\u001b[0m in \u001b[0;36mdone\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;34m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGraphBubbleUp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# This exception is an interruption signal, not an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 )\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6da0ee071afc>\u001b[0m in \u001b[0;36minitial_analysis_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"memory\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_analysis_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmsgs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubgraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Initial analysis result: {result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1777\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1780\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 )\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/chat_agent_executor.py\u001b[0m in \u001b[0;36mcall_model\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAgentState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunnableConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAgentState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0m_validate_chat_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_runnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;31m# add agent name to the AIMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5358\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5359\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5360\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5361\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5362\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         return cast(\n\u001b[1;32m    283\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    859\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 results.append(\n\u001b[0;32m--> 690\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    691\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    926\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid schema for function 'GetData': [{'type': 'integer'}, {'type': 'string'}] is not of type 'object', 'boolean'.\", 'type': 'invalid_request_error', 'param': 'tools[5].function.parameters', 'code': 'invalid_function_parameters'}}"
          ]
        }
      ],
      "source": [
        "\n",
        "received = []\n",
        "\n",
        "# initial_analysis_agent.get_state_history(config)\n",
        "sample_prompt_final = HumanMessage(content=sample_prompt[1], name=\"user\")\n",
        "\n",
        "# try:\n",
        "for s in data_detective_graph.stream({\"messages\": [sample_prompt_final], \"user_prompt\":sample_prompt[1],\"_config\":config, \"df_ids\":[df_id]},config,stream_mode=\"updates\",subgraphs=True, debug=False):\n",
        "  # pprint(f\"State: {s}/n/n\")\n",
        "  pprint(s)\n",
        "  print(\"\\n\")\n",
        "  # print(f\"Current State: {data_detective_graph.get_state(config)}\")\n",
        "  # if \"supervisor\" in s[1]:\n",
        "  #   message = s[1][\"supervisor\"][\"messages\"][-1]\n",
        "  #   if isinstance(message, tuple):\n",
        "  #     pprint(f\"Message: {message[1]}\")\n",
        "  #     received.append(message)\n",
        "  #   else:\n",
        "  #     pprint(f\"Message: /n\")\n",
        "  #     message.pretty_print()\n",
        "  #     received.append(message)\n",
        "  # else:\n",
        "  #   # if isinstance(s[1], ToolMessage) or isinstance(s[1], ToolMessageChunk) or isinstance(s[1], ToolCall):\n",
        "  #     pprint(f\"Message: {s[1]}\")\n",
        "  #     received.append(s[1])\n",
        "    # else:\n",
        "    #   continue\n",
        "    # pprint(f\"Skipping state as 'supervisor' is not present in s[1]. Current subgraph: {list(s[1].keys())[0]}\")\n",
        "    # pprint(f\"Message: {s[1]}\")\n",
        "    # received.append(s[1])\n",
        "  # pprint(s)\n",
        "# except Exception as e:\n",
        "  # pprint(f\"Error: {e}\")\n",
        "  # pprint(f\"Messages received: {received}\")\n",
        "  # pprint(f\"Current State: {data_detective_graph.get_state(config)}\")\n",
        "  # pprint(e)\n",
        "pprint(list(data_detective_graph.get_state_history(config)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBK-Q-qH9yas"
      },
      "outputs": [],
      "source": [
        "    last_state = data_detective_graph.get_state(config)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    pprint(f\"Analyst result summary: {last_state[0]['analysis_insights'].summary}\")\n",
        "    print(\"\\n\")\n",
        "    pprint(f\"Analyst result correlation_insights: {last_state[0]['analysis_insights'].correlation_insights}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    pprint(f\"Analyst result anomaly_insights: {last_state[0]['analysis_insights'].anomaly_insights}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    pprint(f\"Analyst result recommended_visualizations: {last_state[0]['analysis_insights'].recommended_visualizations}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgRwWoBT3bpU"
      },
      "outputs": [],
      "source": [
        "from functools import cache\n",
        "from io import BytesIO\n",
        "from google.colab import drive\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing Pydantic v2 model_validator migration and behavior\n",
        "from pydantic import ValidationError\n",
        "\n",
        "# Valid cases\n",
        "print(GetDataParams(df_id='test', index=0, columns='all'))\n",
        "print(GetDataParams(df_id='test', index=[0,1], columns='all'))\n",
        "print(GetDataParams(df_id='test', index=(0,2), columns='all'))\n",
        "\n",
        "# Invalid cases to confirm ValidationError\n",
        "for invalid in ['invalid', (1,), [1,'a']]:\n",
        "    try:\n",
        "        GetDataParams(df_id='test', index=invalid, columns='all')\n",
        "    except ValidationError as e:\n",
        "        print(f\"Caught expected ValidationError for index={invalid}: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
