{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvqEP-kxAmiX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Attempt to detect Colab environment\n",
        "is_colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if is_colab:\n",
        "    from google.colab import userdata\n",
        "    print(\"Running on CoLab\")\n",
        "    tavily_key = userdata.get('TAVILY_API_KEY')\n",
        "    oai_key = userdata.get('OPENAI_API_KEY')\n",
        "else:\n",
        "    print(\"Not running on CoLab, attempting to load keys from environment variables.\")\n",
        "    tavily_key = os.environ.get('TAVILY_API_KEY')\n",
        "    oai_key = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install -qU \"langchain-community>=0.2.11\" tavily-python openpyxl scipy\n",
        "!pip install -qU langchain langchain-core langchain-openai langchain_experimental langgraph chromadb pydantic python-dotenv tiktoken openpyxl scipy\n",
        "\n",
        "if tavily_key:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = tavily_key\n",
        "else:\n",
        "    print(\"TAVILY_API_KEY not found.\")\n",
        "\n",
        "if not oai_key:\n",
        "    print(\"OPENAI_API_KEY not found.\")\n",
        "\n",
        "def check_and_install(package_name):\n",
        "    try:\n",
        "        subprocess.check_output(['pip', 'show', package_name])\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"{package_name} not found, installing...\")\n",
        "        subprocess.check_output(['pip', 'install', package_name])\n",
        "    else:\n",
        "        print(f\"{package_name} already installed.\")\n",
        "\n",
        "# Ensure pydantic is upgraded if necessary\n",
        "!pip install -U pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "essential_imports_cell"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "import uuid\n",
        "from collections import OrderedDict\n",
        "from tempfile import TemporaryDirectory\n",
        "import io\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from typing import Dict, Optional, List, Tuple, Union, Annotated, Literal\n",
        "from pydantic import BaseModel, Field, validator, model_validator\n",
        "\n",
        "from langchain_core.tools import tool, InjectedToolArg\n",
        "from langchain.tools import Tool\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain_core.language_models.chat_models import BaseChatModel\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage, trim_messages, ToolMessageChunk, ToolCall\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langchain_core.stores import BaseStore\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langgraph.types import Command\n",
        "from scipy import stats\n",
        "import kagglehub\n",
        "from IPython.display import Image, display\n",
        "from tavily import TavilyClient # Added for search_web_for_context tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "working_directory_definition_cell"
      },
      "outputs": [],
      "source": [
        "_TEMP_DIRECTORY = TemporaryDirectory()\n",
        "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
        "print(f\"Working directory set to: {WORKING_DIRECTORY}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1NHB1z5BNWo"
      },
      "outputs": [],
      "source": [
        "# Pydantic models, DataFrameRegistry, global_df_registry, State model\n",
        "# Imports like pydantic, typing, uuid, OrderedDict, Path, AgentState, RunnableConfig, BaseChatModel, PromptTemplate are assumed from essential_imports_cell\n",
        "\n",
        "class CleaningMetadata(BaseModel):\n",
        "    \"\"\"Metadata about the data cleaning actions taken.\"\"\"\n",
        "    steps_taken: list[str] = Field(description=\"List of cleaning steps performed.\")\n",
        "    data_description_after_cleaning: str = Field(description=\"Brief description of the dataset after cleaning.\")\n",
        "\n",
        "class InitialDescription(BaseModel):\n",
        "    \"\"\"Initial description of the dataset.\"\"\"\n",
        "    dataset_description: str = Field(description=\"Brief description of the dataset.\")\n",
        "    data_sample: Optional[str] = Field(description=\"Sample of the data (first few rows).\")\n",
        "\n",
        "class AnalysisInsights(BaseModel):\n",
        "    \"\"\"Insights from the exploratory data analysis.\"\"\"\n",
        "    summary: str = Field(description=\"Overall summary of EDA findings.\")\n",
        "    correlation_insights: str = Field(description=\"Key correlation insights identified.\")\n",
        "    anomaly_insights: str = Field(description=\"Anomalies or interesting patterns detected.\")\n",
        "    recommended_visualizations: list[str] = Field(description=\"List of recommended visualizations to illustrate findings.\")\n",
        "    recommended_next_steps: Optional[List[str]] = Field(None, description=\"List of recommended next analysis steps or questions to investigate based on the findings.\")\n"
        "\n",
        "class VisualizationResults(BaseModel):\n",
        "    \"\"\"Results from the visualization generation.\"\"\"\n",
        "    visualizations: List[dict] = Field(description=\"List of visualizations generated. Each dictionary should have the plot type and the base64 encoded image\")\n",
        "\n",
        "class ReportResults(BaseModel):\n",
        "    \"\"\"Results from the report generation.\"\"\"\n",
        "    report_path: str = Field(description=\"Path to the generated report file.\")\n",
        "\n",
        "class DataQueryParams(BaseModel):\n",
        "    \"\"\"Parameters for querying the DataFrame.\"\"\"\n",
        "    columns: List[str] = Field(..., description=\"List of columns to include in the output\")\n",
        "    filter_column: Optional[str] = Field(None, description=\"Column to apply the filter on\")\n",
        "    filter_value: Optional[str] = Field(None, description=\"Value to filter the rows by\")\n",
        "    operation: str = Field(\"select\", description=\"Operation to perform: 'select', 'sum', 'mean', 'count', 'max', 'min', 'median', etc.\")\n",
        "\n",
        "# schema_extra_cols and schema_extra_cells removed as they are no longer used.\n",
        "\n",
        "class CellIdentifier(BaseModel):\n",
        "    \"\"\"Identifies a single cell by row index and column name.\"\"\"\n",
        "    row_index: int = Field(..., description=\"Row index of the cell.\")\n",
        "    column_name: str = Field(..., description=\"Column name of the cell.\")\n",
        "\n",
        "class GetDataParams(BaseModel):\n",
        "    \"\"\"Parameters for retrieving data from the DataFrame.\"\"\"\n",
        "    df_id: str = Field(..., description=\"DataFrame ID in the global registry.\")\n",
        "    index: Union[int, List[int], Tuple[int, int]] = Field(..., description=\"Specifies the rows to retrieve. Can be: 1) A single integer for one row. 2) A list of integers for multiple specific rows. 3) A 2-element tuple `(start, end)` for a range of rows (inclusive).\")\n",
        "    columns: Union[str, List[str]] = Field(\"all\", description=\"A string (single column), a list of strings (multiple columns), or 'all' for all columns (default: 'all').\")\n",
        "    cells: Optional[List[CellIdentifier]] = Field(None, description=\"A list of cell identifier objects, each specifying a 'row_index' and 'column_name'.\")\n",
        "\n",
        "    @model_validator(mode='before')\n",
        "    def validate_index(cls, values):\n",
        "        index = values.get('index')\n",
        "        if not isinstance(index, (int, list, tuple)):\n",
        "            raise ValueError(\"Invalid 'index' type. Must be int, list, or tuple.\")\n",
        "        if isinstance(index, tuple) and len(index) != 2:\n",
        "            raise ValueError(\"Invalid tuple length for 'index'. Must be a 2-tuple for range.\")\n",
        "        if isinstance(index, list) and not all(isinstance(i, int) for i in index):\n",
        "            raise ValueError(\"Invalid list elements for 'index'. Must contain only integers.\")\n",
        "        return values\n",
        "\n",
        "class DataFrameRegistry:\n",
        "    def __init__(self, capacity=20):\n",
        "        self.registry: Dict[str, dict] = {}\n",
        "        self.df_id_to_raw_path: Dict[str, str] = {}\n",
        "        self.cache = OrderedDict() \n",
        "        self.capacity = capacity\n",
        "\n",
        "    def register_dataframe(self, df=None, df_id=None, raw_path=\"\"):\n",
        "        if df_id is None:\n",
        "            df_id = str(uuid.uuid4())\n",
        "        if raw_path == \"\":\n",
        "            # WORKING_DIRECTORY is now guaranteed to be defined before this class is instantiated\n",
        "            raw_path = WORKING_DIRECTORY / f\"{df_id}.csv\"\n",
        "        self.registry[df_id] = {\"df\": df, \"raw_path\": str(raw_path)}\n",
        "        self.df_id_to_raw_path[df_id] = str(raw_path)\n",
        "        if df is not None:\n",
        "            self.cache[df_id] = df\n",
        "            if len(self.cache) > self.capacity:\n",
        "                self.cache.popitem(last=False)\n",
        "        return df_id\n",
        "\n",
        "    def get_dataframe(self, df_id: str, load_if_not_exists=False):\n",
        "        if df_id in self.cache:\n",
        "            self.cache.move_to_end(df_id)\n",
        "            return self.cache[df_id]\n",
        "        \n",
        "        if df_id in self.registry:\n",
        "            df_data = self.registry[df_id]\n",
        "            df = df_data.get(\"df\")\n",
        "            if df is not None:\n",
        "                self.cache[df_id] = df\n",
        "                if len(self.cache) > self.capacity:\n",
        "                    self.cache.popitem(last=False)\n",
        "                return df\n",
        "            elif load_if_not_exists and df_data.get(\"raw_path\"):\n",
        "                try:\n",
        "                    loaded_df = pd.read_csv(df_data[\"raw_path\"])\n",
        "                    self.registry[df_id][\"df\"] = loaded_df\n",
        "                    self.cache[df_id] = loaded_df\n",
        "                    if len(self.cache) > self.capacity:\n",
        "                        self.cache.popitem(last=False)\n",
        "                    return loaded_df\n",
        "                except FileNotFoundError:\n",
        "                    return None \n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading DataFrame from {df_data['raw_path']}: {e}\")\n",
        "                    return None\n",
        "        return None\n",
        "\n",
        "    def remove_dataframe(self, df_id: str):\n",
        "        if df_id in self.registry:\n",
        "            del self.registry[df_id]\n",
        "            if df_id in self.cache:\n",
        "                del self.cache[df_id]\n",
        "            del self.df_id_to_raw_path[df_id]\n",
        "    def get_raw_path_from_id(self, df_id: str):\n",
        "        return self.df_id_to_raw_path.get(df_id)\n",
        "\n",
        "global_df_registry = DataFrameRegistry()\n",
        "\n",
        "class State(AgentState):\n",
        "  next: str\n",
        "  user_prompt: str\n",
        "  df_ids: List[str] = Field(default_factory=list)\n",
        "  _config: Optional[RunnableConfig] = None\n",
        "  initial_description: Optional[InitialDescription] = None\n",
        "  cleaning_metadata: Optional[CleaningMetadata] = None\n",
        "  analysis_insights: Optional[AnalysisInsights] = None\n",
        "  initial_analysis_agent: Optional[BaseChatModel] = None\n",
        "  data_cleaner_agent: Optional[BaseChatModel] = None\n",
        "  analyst_agent: Optional[BaseChatModel] = None\n",
        "  initial_analysis_complete: Optional[bool] = False\n",
        "  data_cleaning_complete: Optional[bool] = False\n",
        "  analyst_complete: Optional[bool] = False\n",
        "  file_writer_complete: Optional[bool] = False\n",
        "  _count_: int = 0\n",
        "  _id_: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
        "  visualization_results: Optional[VisualizationResults] = None\n",
        "  visualization_complete: Optional[bool] = False\n",
        "  report_results: Optional[ReportResults] = None\n",
        "  report_generator_complete: Optional[bool] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prompt_templates_cell"
      },
      "outputs": [],
      "source": [
        "data_cleaner_prompt_template = PromptTemplate(\n",
        "    input_variables=['dataset_description', 'data_sample', 'tool_descriptions', 'output_format', 'available_df_ids'],\n",
        "    template=\"\"\"You are a Data Cleaner Agent equipped with tools to clean and preprocess a dataset.\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    Here's a description of the dataset: {dataset_description}\n",
        "    Here's a sample of the data (first few rows):\n",
        "    {data_sample}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    You have access to a tool called `query_dataframe` for querying the DataFrame.\n",
        "    Refer to the tool's docstring for detailed usage instructions and examples.\n",
        "    You can get the column names with `get_column_names`, and get any specified data from the dataframe using `get_data`.\n",
        "\n",
        "    Identify potential issues like missing values, outliers, incorrect data types, and inconsistencies.\n",
        "    Propose and execute a cleaning strategy, step-by-step, using the provided tools.\n",
        "    For each step, clearly state the tool you are using and the parameters.\n",
        "    Explain your reasoning for each cleaning step.\n",
        "\n",
        "    Example Plan & Execution:\n",
        "    Step 1: Check for missing values in each column using the 'CheckMissingValues' tool with input 'df_id'.\n",
        "    Step 2: If 'Age' column has missing values, fill them using the 'FillMissingMedian' tool with input 'df_id' and 'column_name' as 'Age'.\n",
        "    ... and so on.\n",
        "\n",
        "    After cleaning, summarize the actions taken and describe the current state of the dataset in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "\n",
        "    Let's begin! What is your data cleaning plan and execution using tools, and structured output?\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "analyst_prompt_template_initial = PromptTemplate(\n",
        "    input_variables=['user_prompt', 'tool_descriptions', 'output_format','available_df_ids'],\n",
        "    template=\"\"\"You are an Data Describer and Sampler. Your role is to perform exploratory data analysis (EDA) on a dataset.\n",
        "    Here's a text description of the dataset: {user_prompt}\n",
        "\n",
        "    First, we need a basic description of the dataset, along with a sample of the data, to pass to the Data Cleaner Agent.\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    Describe the dataset in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "    FIRST, think of a step by step plan for how to proceed with collecting the data you need, when to stop collecting, and how and when to report back in the requested format.\n",
        "\n",
        "    Using your tools in a conservative manner, please 1. Write a text description of the dataset based on a few strategically used tool calls, and write it to dataset_description attribute.\n",
        "    Then, 2. use your tools to produce a sample of the data for the data_sample attribute.\n",
        "\n",
        "    Do not make unnecessary or repeated tool calls! Report straight to the Supervisor with the expected output format.\n",
        "\n",
        "    After performing any necessary tool calls, IMMEDIATELY output your final answer in the specified format. Do NOT make any further tool calls!\n",
        "    You do not need to perform the functions of other agents, do your job and submit the results.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "analyst_prompt_template_main = PromptTemplate(\n",
        "    input_variables=['cleaned_dataset_description', 'cleaning_metadata', 'tool_descriptions', 'output_format','available_df_ids'],\n",
        "    template=\"\"\"You are an Analyst Agent. Your role is to perform exploratory data analysis (EDA) on a cleaned dataset.\n",
        "    Here's a description of the cleaned dataset: {cleaned_dataset_description}\n",
        "    Here's metadata about the data cleaning actions taken: {cleaning_metadata}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    You have access to a tool called `query_dataframe` for querying the DataFrame.\n",
        "    Refer to the tool's docstring for detailed usage instructions and examples.\n",
        "    You can get the column names with `get_column_names`, and get any specified data from the dataframe using `get_data`.\n",
        "\n",
        "    Perform EDA to understand the dataset. Include:\n",
        "    - Descriptive statistics (mean, median, mode, standard deviation, etc.) for relevant columns.\n",
        "    - Identify potential correlations between features.\n",
        "    - Highlight any anomalies or interesting patterns you find.\n",
        "    - Reason step-by-step about your analysis (Chain-of-Thought).\n",
        "    - Recommend visualizations that would best illustrate your findings.\n",
        "    - Suggest potential next steps for deeper analysis or further questions to investigate based on your findings.\n",
        "\n",
        "    Output should be a summary of your EDA findings, insights, recommended visualizations, and next steps, based on your tool usage, all written into the\n"
        "    {output_format} class.\n",
        "\n",
        "    Let's begin! What are your EDA insights and visualization recommendations using tools?\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "file_writer_prompt_template = PromptTemplate(\n",
        "    input_variables=['file_name', 'content', 'file_type','tool_descriptions','available_df_ids'],\n",
        "    template= \"\"\"You are an agent that specializes in writing data to a file in the format of {file_type}. You are one member of a data analysis team. You ONLY write content as requested in a analyst-friendly manner. Leaver other tasks to other agents on the team.\n",
        "    You have the following tools at your disposal:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    Write the following content to a file named {file_name}:\n",
        "    {content}\n",
        "    \"\"\",\n",
        ")\n",
        "visualization_prompt_template = PromptTemplate(\n",
        "    input_variables=[\n",
        "        \"cleaned_dataset_description\",\n",
        "        \"analysis_insights\",\n",
        "        \"tool_descriptions\",\n",
        "        \"output_format\",\n",
        "        \"available_df_ids\",\n",
        "    ],\n",
        "    template=\"\"\"You are a Visualization Agent equipped with tools to create visualizations.\n",
        "    Here's a description of the cleaned dataset: {cleaned_dataset_description}\n",
        "    Here are the insights from the Analyst Agent and the list of visualizations to create: {analysis_insights}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    Create the visualizations step-by-step, using the provided tools.\n",
        "    For each step, clearly state the tool you are using and the parameters.\n",
        "    Explain your reasoning for each visualization.\n",
        "\n",
        "    After creating the visualizations, summarize the actions taken and describe the current state of the visualizations in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "\n",
        "    Let's begin!\n",
        "    What is your visualization plan and execution using tools, and structured output?\n",
        "    \"\"\",\n",
        ")\n",
        "report_generator_prompt_template = PromptTemplate(\n",
        "    input_variables=[\n",
        "        \"cleaning_metadata\",\n",
        "        \"analysis_insights\",\n",
        "        \"visualization_results\",\n",
        "        \"tool_descriptions\",\n",
        "        \"output_format\",\n",
        "        \"available_df_ids\",\n",
        "    ],\n",
        "    template=\"\"\"You are a Report Generator Agent equipped with tools to generate reports.\n",
        "    Here's the metadata about the data cleaning actions taken: {cleaning_metadata}\n",
        "    Here are the insights from the Analyst Agent: {analysis_insights}\n",
        "    Here are the visualization results: {visualization_results}\n",
        "\n",
        "    Your available tools are:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    The df_ids you can use to access the data are: {available_df_ids}\n",
        "\n",
        "    Generate a structured report that combines textual explanations, statistics, and visualizations.\n",
        "    Explain your reasoning for the report structure.\n",
        "\n",
        "    After generating the report, summarize the actions taken and describe the current state of the report in a structured JSON format following this schema:\n",
        "    {output_format}\n",
        "\n",
        "    Let's begin!\n",
        "    What is your report generation plan and execution using tools, and structured output?\n",
        "    \"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tool_definitions_cell"
      },
      "outputs": [],
      "source": [
        "# Added imports for create_histogram\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "# Tools from original cell 4 (rzo9i8HtDrmO)\n",
        "@tool(name_or_callable=\"GetDataframeSchema\",response_format=\"content_and_artifact\")\n",
        "def get_dataframe_schema() -> tuple[str, dict]:\n",
        "    \"\"\"Return a summary of the DataFrame's schema and sample data.\"\"\"\n",
        "    try:\n",
        "        # Assuming 'df' is accessible here, which might be an issue.\n",
        "        # This tool might need a df_id parameter and use global_df_registry\n",
        "        # For now, keeping original structure but noting this potential issue.\n",
        "        schema = {\n",
        "            \"columns\": list(df.columns), # 'df' might be undefined here\n",
        "            \"dtypes\": df.dtypes.astype(str).to_dict(),\n",
        "            \"sample\": df.head(3).to_dict(orient=\"records\")\n",
        "        }\n",
        "        return \"\", {\"schema\": schema}\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", {}\n",
        "\n",
        "@tool(\"GetColumnNames\")\n",
        "def get_column_names(df_id: str) -> str:\n",
        "    \"\"\"Useful to get the names of the columns in the current DataFrame.\"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "            df = pd.read_csv(raw_path)\n",
        "            global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        if df is None:\n",
        "            return f\"Error: DataFrame with ID '{df_id}' not found.\"\n",
        "        if df.empty:\n",
        "            return f\"Warning: DataFrame '{df_id}' is empty. No columns available.\"\n",
        "        cols = df.columns.tolist()\n",
        "        return \", \".join(cols)\n",
        "    except FileNotFoundError as e:\n",
        "        return f\"Error loading DataFrame from path: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error getting column names for DataFrame '{df_id}': {e}\"\n",
        "\n",
        "@tool(\"CheckMissingValues\")\n",
        "def check_missing_values(df_id: str) -> str:\n",
        "    \"\"\"Checks for missing values in a pandas DataFrame and returns a summary.\"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "            df = pd.read_csv(raw_path)\n",
        "            global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        if df is None:\n",
        "            return f\"Error: DataFrame with ID '{df_id}' not found.\"\n",
        "        missing = df.isnull().sum()\n",
        "        if missing.sum() == 0:\n",
        "            return f\"No missing values in DataFrame '{df_id}'.\"\n",
        "        return missing.to_string()\n",
        "    except FileNotFoundError as e:\n",
        "        return f\"Error loading DataFrame from path: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error checking missing values for DataFrame '{df_id}': {e}\"\n",
        "\n",
        "@tool(\"DropColumn\")\n",
        "def drop_column(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"Drops a specified column from the DataFrame.\"\"\"\n",
        "    pprint(f\"Dropping column {column_name} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    try:\n",
        "        if df is None:\n",
        "          try:\n",
        "            raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "            df = pd.read_csv(raw_path)\n",
        "            global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "          except Exception as e:\n",
        "            return f\"Error loading DataFrame: {e}\"\n",
        "        if column_name not in df.columns:\n",
        "            return f\"Error: Column '{column_name}' not found in DataFrame '{df_id}'. Available columns: {list(df.columns)}\"\n",
        "        df_dropped = df.drop(columns=[column_name])\n",
        "        # The change is not persisted in global_df_registry here. This might be intended or an oversight.\n",
        "        return \"Column dropped successfully. New columns: \" + \", \".join(df_dropped.columns.tolist())\n",
        "    except Exception as e:\n",
        "        return f\"Error dropping column: {e}\"\n",
        "\n",
        "@tool\n",
        "def delete_rows(df_id: str, conditions: Union[str, List[str], Dict], inplace: bool = True) -> str:\n",
        "    \"\"\"Deletes rows from the DataFrame based on specified conditions.\"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if not isinstance(conditions, (str, list, dict)):\n",
        "            return f\"Error: 'conditions' must be a string, list of strings, or dict. Received type: {type(conditions).__name__}\"\n",
        "        if df is None:\n",
        "          try:\n",
        "            raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "            df = pd.read_csv(raw_path)\n",
        "            global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "          except Exception as e:\n",
        "            return f\"Error loading DataFrame: {e}\"\n",
        "        \n",
        "        # Original df is queried, but result not assigned back if inplace is False or for intermediate steps.\n",
        "        # If inplace=True, df.drop(df.index, inplace=True) would drop from the original df object in registry if mutable.\n",
        "        # This logic seems complex and might not behave as expected regarding persistence.\n",
        "        queried_df = df # Start with the original df\n",
        "        if isinstance(conditions, str):\n",
        "            queried_df = df.query(conditions) # This creates a new df\n",
        "        elif isinstance(conditions, list):\n",
        "            temp_df = df\n",
        "            for condition in conditions:\n",
        "                temp_df = temp_df.query(condition)\n",
        "            queried_df = temp_df\n",
        "        elif isinstance(conditions, dict):\n",
        "            temp_df = df\n",
        "            for condition_type, condition_list in conditions.items():\n",
        "                if not isinstance(condition_list, list):\n",
        "                    return f\"Error: condition list for '{condition_type}' must be a list.\"\n",
        "                for condition in condition_list:\n",
        "                    temp_df = temp_df.query(condition)\n",
        "            queried_df = temp_df\n",
        "        else:\n",
        "            return f\"Error: Invalid conditions format. Received type: {type(conditions).__name__}\"\n",
        "\n",
        "        if queried_df.empty:\n",
        "            return f\"No rows match the provided condition(s): {conditions}\"\n",
        "\n",
        "        if inplace:\n",
        "            # This will modify the DataFrame object 'df' obtained from registry if it's the same object.\n",
        "            # Pandas operations often return new DataFrames, so care is needed here for true inplace modification of registry's copy.\n",
        "            df.drop(queried_df.index, inplace=True) # df is the original from registry, queried_df might be a view or copy.\n",
        "            return \"Rows deleted successfully.\"\n",
        "        else:\n",
        "            return queried_df.to_json() \n",
        "    except Exception as e:\n",
        "        return f\"Error deleting rows: {e}\"\n",
        "\n",
        "@tool(\"FillMissingMedian\")\n",
        "def fill_missing_median(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"Fills missing values in a specified column with the median.\"\"\"\n",
        "    pprint(f\"Filling missing values in column {column_name} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "      if column_name not in df.columns:\n",
        "          return f\"Error: Column '{column_name}' not found in DataFrame '{df_id}'.\"\n",
        "      if not pd.api.types.is_numeric_dtype(df[column_name]):\n",
        "          return f\"Error: Column '{column_name}' in DataFrame '{df_id}' is not numeric and cannot compute median.\"\n",
        "      median_value = df[column_name].median()\n",
        "      df[column_name].fillna(median_value, inplace=True) # Modified to be inplace on the actual df from registry\n",
        "      return f\"Missing values in column '{column_name}' filled with median: {median_value}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error filling missing values: {e}\"\n",
        "\n",
        "data_cleaning_tools = [\n",
        "    Tool(name=\"GetDataFrameSchema\", func=get_dataframe_schema, description=\"Useful to get a summary of the DataFrame's schema and sample data.\"),\n",
        "    Tool(name=\"GetColumnNames\", func=get_column_names, description=\"Useful to get the names of the columns in the current DataFrame. Input should be 'df_id'.\"),\n",
        "    Tool(name=\"CheckMissingValues\", func=check_missing_values, description=\"Useful to check for missing values in the DataFrame. Input should be 'df_id'.\"),\n",
        "    Tool(name=\"DropColumn\", func=drop_column, description=\"Useful to drop a column from the DataFrame. Input should be 'df_id' and 'column_name'.\"),\n",
        "    Tool(name=\"DeleteRows\", func=delete_rows, description=\"Useful to delete rows from the DataFrame based on specified conditions. Input should be 'df_id', 'conditions', and 'inplace'.\"),\n",
        "    Tool(name=\"FillMissingMedian\", func=fill_missing_median, description=\"Useful to fill missing values in a specific column using the median. Input should be 'df_id' and 'column_name'.\"),\n",
        "]\n",
        "\n",
        "# Tools from original cell 5 (8Yb-OklIFuFw)\n",
        "@tool(name_or_callable=\"QueryDataframe\",response_format=\"content_and_artifact\")\n",
        "def query_dataframe(params: DataQueryParams, df_id: str) -> tuple[str, dict]:\n",
        "    \"\"\"Query the DataFrame based on specified columns, filter, and operation.\"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            try:\n",
        "              raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "              df = pd.read_csv(raw_path)\n",
        "              # raw_path argument was duplicated in original: register_dataframe(df, df_id, raw_path, raw_path)\n",
        "              global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "            except Exception as e:\n",
        "                return f\"Error loading DataFrame: {e}\", {}\n",
        "\n",
        "        if params.filter_column and params.filter_column not in df.columns:\n",
        "            return \"Error: Filter column does not exist.\", {}\n",
        "\n",
        "        if params.filter_column:\n",
        "            filtered_df = df[df[params.filter_column] == params.filter_value]\n",
        "        else:\n",
        "            filtered_df = df\n",
        "\n",
        "        if params.operation == \"select\":\n",
        "            result = filtered_df[params.columns].to_dict(orient=\"records\")\n",
        "        elif params.operation == \"sum\":\n",
        "            result = filtered_df[params.columns].sum(numeric_only=True).to_dict()\n",
        "        elif params.operation == \"mean\":\n",
        "            result = filtered_df[params.columns].mean(numeric_only=True).to_dict()\n",
        "        elif params.operation == \"count\":\n",
        "            result = filtered_df[params.columns].count().to_dict()\n",
        "        else:\n",
        "            return f\"Unsupported operation: {params.operation}\", {}\n",
        "\n",
        "        return \"Query successful.\", {\"result\": result}\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", {}\n",
        "\n",
        "@tool(name_or_callable=\"GetData\", response_format=\"content_and_artifact\")\n",
        "def get_data(params: GetDataParams, df_id: str = \"\") -> str:\n",
        "    \"\"\"Retrieves data from a DataFrame by ID, for flexible row/column selection and retrieval specific cells.\"\"\"\n",
        "    if not df_id: df_id = params.df_id\n",
        "    elif df_id.strip() != params.df_id.strip(): return \"Error: df_id mismatch.\"\n",
        "\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "            return f\"Error loading DataFrame: {e}\"\n",
        "    \n",
        "    index, columns, cells = params.index, params.columns, params.cells\n",
        "    if cells is not None:\n",
        "        output_str = \"\"\n",
        "        for row_index, col_name in cells:\n",
        "            val = df.loc[row_index, col_name]\n",
        "            output_str += f\"Value at ({row_index}, {col_name}): {val}\\n\"\n",
        "        return output_str\n",
        "\n",
        "    if isinstance(index, int): rows = df.iloc[[index]]\n",
        "    elif isinstance(index, list): rows = df.iloc[index]\n",
        "    elif isinstance(index, tuple): rows = df.iloc[index[0]:index[1]] # Slicing with iloc\n",
        "    else: return \"Error: Invalid index format.\"\n",
        "\n",
        "    if columns == \"all\": columns_to_include = df.columns\n",
        "    elif isinstance(columns, str): columns_to_include = [columns]\n",
        "    elif isinstance(columns, list): columns_to_include = columns\n",
        "    else: return \"Error: Invalid columns format.\"\n",
        "\n",
        "    selected_data = rows[columns_to_include]\n",
        "    output_str = \"\"\n",
        "    for row_idx, row_data in selected_data.iterrows():\n",
        "        output_str += f\"Row {row_idx}:\\n\"\n",
        "        for col, val in row_data.items():\n",
        "            output_str += f\"  {col}: {val}\\n\"\n",
        "    return output_str\n",
        "\n",
        "@tool(\"GetDescriptiveStatistics\")\n",
        "def get_descriptive_statistics(df_id: str, column_names: str = \"all\") -> str:\n",
        "    \"\"\"Calculates descriptive statistics for specified columns in the DataFrame.\"\"\"\n",
        "    pprint(f\"Getting descriptive statistics for {column_names} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "      columns_to_describe = df.columns if column_names.lower() == 'all' or not column_names else column_names.split(',')\n",
        "      # Ensure all columns exist\n",
        "      missing_cols = [col for col in columns_to_describe if col not in df.columns]\n",
        "      if missing_cols:\n",
        "          return f\"Error: Columns not found: {', '.join(missing_cols)}\"\n",
        "      desc_stats = df[columns_to_describe].describe()\n",
        "      return desc_stats.to_string()\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating descriptive statistics: {e}\"\n",
        "\n",
        "@tool(\"CalculateCorrelation\")\n",
        "def calculate_correlation(df_id: str, column1_name: str, column2_name: str) -> str:\n",
        "    \"\"\"Calculates the Pearson correlation coefficient between two columns.\"\"\"\n",
        "    pprint(f\"Calculating correlation between {column1_name} and {column2_name} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "      if column1_name not in df.columns or column2_name not in df.columns:\n",
        "          return f\"Error: One or both columns not found.\"\n",
        "      correlation = df[column1_name].corr(df[column2_name])\n",
        "      return f\"Correlation between '{column1_name}' and '{column2_name}': {correlation}\"\n",
        "    except Exception as e:\n",
        "      return f\"Error calculating correlation: {e}\"\n",
        "\n",
        "@tool(\"PerformHypothesisTest\")\n",
        "def perform_hypothesis_test(df_id: str, column_name: str, value: float) -> str:\n",
        "    \"\"\"Performs a one-sample t-test.\"\"\"\n",
        "    pprint(f\"Performing hypothesis test on {column_name} with value {value} from {df_id}\")\n",
        "    df = global_df_registry.get_dataframe(df_id)\n",
        "    try:\n",
        "      if df is None:\n",
        "        try:\n",
        "          raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "          df = pd.read_csv(raw_path)\n",
        "          global_df_registry.register_dataframe(df, df_id, raw_path)\n",
        "        except Exception as e:\n",
        "          return f\"Error loading DataFrame: {e}\"\n",
        "      if column_name not in df.columns:\n",
        "            return f\"Error: Column {column_name} not found.\"\n",
        "      column_data = df[column_name].dropna()\n",
        "      if not pd.api.types.is_numeric_dtype(column_data):\n",
        "            return \"Error: Hypothesis test can only be performed on numeric columns.\"\n",
        "      t_statistic, p_value = stats.ttest_1samp(a=column_data, popmean=value)\n",
        "      alpha = 0.05\n",
        "      result = f\"Reject null hypothesis. Mean is significantly different from {value}.\" if p_value < alpha else f\"Fail to reject null hypothesis. Mean is not significantly different from {value}.\"\n",
        "      return result + f\" T-statistic: {t_statistic}, P-value: {p_value}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error performing hypothesis test: {e}\"\n",
        "\n",
        "analyst_tools = [get_dataframe_schema,get_descriptive_statistics, calculate_correlation, perform_hypothesis_test, get_column_names, get_data,query_dataframe]\n",
        "\n",
        "# Tools from original cell 6 (cJ1tuCJZdkXk)\n",
        "@tool\n",
        "def create_sample(points: Annotated[List[str], \"List of main points or sections.\"], file_name: Annotated[str, \"File path to save the outline.\"]) -> Annotated[str, \"Path of the saved file of sample data from the dataset.\"]:\n",
        "    \"\"\"Create and save an outline.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        for i, point in enumerate(points):\n",
        "            file.write(f\"{i + 1}. {point}\\n\")\n",
        "    return f\"sample data saved to {file_name}\"\n",
        "\n",
        "@tool\n",
        "def read_file(file_name: Annotated[str, \"File path to read the file from.\"], start: Annotated[Optional[int], \"The start line. Default is 0\"] = None, end: Annotated[Optional[int], \"The end line. Default is None\"] = None) -> str:\n",
        "    \"\"\"Read the specified data file.\"\"\"\n",
        "    pprint(f\"Reading file {file_name} from {WORKING_DIRECTORY} \\n with start {start} and end {end}\")\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    if start is None: start = 0\n",
        "    if end is None: end = start + 10\n",
        "    return \"\\n\".join(lines[start:end])\n",
        "\n",
        "@tool\n",
        "def write_file(content: Annotated[str, \"Text content to be written into the file.\"], file_name: Annotated[str, \"File path to save the document.\"]) -> Annotated[str, \"Path of the saved document file.\"]:\n",
        "    \"\"\"Create and save a data file of any format.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(content)\n",
        "    return f\"Document saved to {file_name}\"\n",
        "\n",
        "@tool\n",
        "def edit_file(file_name: Annotated[str, \"Path of the file to be edited.\"], inserts: Annotated[Dict[int, str], \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\"]) -> Annotated[str, \"Path of the edited document file.\"]:\n",
        "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    sorted_inserts = sorted(inserts.items())\n",
        "    for line_number, text in sorted_inserts:\n",
        "        if 1 <= line_number <= len(lines) + 1:\n",
        "            lines.insert(line_number - 1, text + \"\\n\")\n",
        "        else:\n",
        "            return f\"Error: Line number {line_number} is out of range.\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.writelines(lines)\n",
        "    return f\"Document edited and saved to {file_name}\"\n",
        "\n",
        "repl = PythonREPL()\n",
        "@tool\n",
        "def python_repl_tool(code: Annotated[str, \"The python code to execute.\"], df_id: Annotated[str, \"The ID of the DataFrame in the global registry.\"]) -> str:\n",
        "    \"\"\"Executes Python code within a REPL environment that has access to the global DataFrame registry.\"\"\"\n",
        "    def get_df_from_registry(df_id_local):\n",
        "        return global_df_registry.get_dataframe(df_id_local)\n",
        "    try:\n",
        "        # Make get_df_from_registry available in the REPL's local scope\n",
        "        repl.globals['get_df_from_registry'] = get_df_from_registry\n",
        "        repl.globals['pd'] = pd # Make pandas available as pd\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    return result\n",
        "\n",
        "analyst_tools.append(python_repl_tool)\n",
        "analyst_tools.append(create_sample)\n",
        "data_cleaning_tools.append(Tool(name=\"WriteFile\",func = write_file,description=\"Useful to create and save a data file of any format.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"PythonREPL\",func = python_repl_tool,description=\"Useful to execute python code. If you want to see the output of a value, you should print it out with `print(...)`. This is visible to the user.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"EditFile\",func = edit_file,description=\"Useful to edit a document by inserting text at specific line numbers.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"QueryDataframe\", func = query_dataframe,description=\"Useful to query a dataframe.\"))\n",
        "data_cleaning_tools.append(Tool(name=\"GetData\",func = get_data,description=\"Useful to retrieve data from the DataFrame with the specified ID, supporting flexible row and column selection, and specific cell retrieval.\"))\n",
        "\n",
        "file_writer_tools = [get_dataframe_schema,write_file, edit_file, read_file, python_repl_tool]\n",
        "visualization_tools = [python_repl_tool,get_dataframe_schema,get_data,get_column_names]\n",
        "report_generator_tools = [python_repl_tool, write_file, edit_file, read_file]\n",
        "\n",
        "@tool\n",
        "def create_histogram(df_id: str, column_name: str) -> dict:\n",
        "    \"\"\"Generates a histogram for a specified numeric column in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the numeric column for which to generate the histogram.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the plot type ('histogram'), column name,\n",
        "        and a base64 encoded PNG image of the histogram,\n",
        "        or an error message string if generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return {\"error\": f\"DataFrame with ID '{df_id}' not found.\"}\n",
        "\n",
        "        if column_name not in df.columns:\n",
        "            return {\"error\": f\"Column '{column_name}' not found in DataFrame '{df_id}'.\"}\n",
        "\n",
        "        if not pd.api.types.is_numeric_dtype(df[column_name]):\n",
        "            return {\"error\": f\"Column '{column_name}' is not numeric and a histogram cannot be generated.\"}\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.histplot(df[column_name], kde=True)\n",
        "        plt.title(f'Histogram of {column_name}')\n",
        "        plt.xlabel(column_name)\n",
        "        plt.ylabel('Frequency')\n",
        "        \n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format=\"png\")\n",
        "        plt.close() # Close the plot to free memory\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "        buf.close()\n",
        "\n",
        "        return {\"plot_type\": \"histogram\", \"column_name\": column_name, \"image_base64\": image_base64}\n",
        "\n",
        "    except Exception as e:\n",
        "        plt.close() # Ensure plot is closed in case of error during generation\n",
        "        return {\"error\": f\"Failed to generate histogram: {str(e)}\"}\n",
        "\n",
        "@tool\n",
        "def create_scatter_plot(df_id: str, x_column_name: str, y_column_name: str) -> dict:\n",
        "    \"\"\"Generates a scatter plot for two specified numeric columns in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        x_column_name: The name of the numeric column for the x-axis.\n",
        "        y_column_name: The name of the numeric column for the y-axis.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the plot type ('scatter'), x-column name,\n",
        "        y-column name, and a base64 encoded PNG image of the scatter plot,\n",
        "        or an error message dictionary if generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return {\"error\": f\"DataFrame with ID '{df_id}' not found.\"}\n",
        "\n",
        "        if x_column_name not in df.columns:\n",
        "            return {\"error\": f\"X-axis column '{x_column_name}' not found in DataFrame '{df_id}'.\"}\n",
        "        if y_column_name not in df.columns:\n",
        "            return {\"error\": f\"Y-axis column '{y_column_name}' not found in DataFrame '{df_id}'.\"}\n",
        "\n",
        "        if not pd.api.types.is_numeric_dtype(df[x_column_name]):\n",
        "            return {\"error\": f\"X-axis column '{x_column_name}' is not numeric.\"}\n",
        "        if not pd.api.types.is_numeric_dtype(df[y_column_name]):\n",
        "            return {\"error\": f\"Y-axis column '{y_column_name}' is not numeric.\"}\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(x=df[x_column_name], y=df[y_column_name])\n",
        "        plt.title(f'Scatter Plot of {y_column_name} vs {x_column_name}')\n",
        "        plt.xlabel(x_column_name)\n",
        "        plt.ylabel(y_column_name)\n",
        "        \n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format=\"png\")\n",
        "        plt.close() # Close the plot to free memory\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "        buf.close()\n",
        "\n",
        "        return {\n",
        "            \"plot_type\": \"scatter\", \n",
        "            \"x_column\": x_column_name, \n",
        "            \"y_column\": y_column_name, \n",
        "            \"image_base64\": image_base64\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        plt.close() # Ensure plot is closed in case of error during generation\n",
        "        return {\"error\": f\"Failed to generate scatter plot: {str(e)}\"}\n",
        "\n",
        "visualization_tools.append(create_histogram)\n",
        "visualization_tools.append(create_scatter_plot)\n",
        "\n",
        "@tool\n",
        "def create_correlation_heatmap(df_id: str, column_names: Optional[List[str]] = None) -> dict:\n",
        "    \"\"\"Generates a correlation heatmap for numeric columns in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_names: Optional list of column names to include.\n",
        "                      If None or empty, all numeric columns are used.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the plot type ('correlation_heatmap')\n",
        "        and a base64 encoded PNG image of the heatmap,\n",
        "        or an error message dictionary if generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return {\"error\": f\"DataFrame with ID '{df_id}' not found.\"}\n",
        "\n",
        "        df_to_correlate = df\n",
        "        if column_names:\n",
        "            missing_cols = [col for col in column_names if col not in df.columns]\n",
        "            if missing_cols:\n",
        "                return {\"error\": f\"Columns not found: {', '.join(missing_cols)}.\"}\n",
        "            df_to_correlate = df[column_names]\n",
        "\n",
        "        df_numeric = df_to_correlate.select_dtypes(include=np.number)\n",
        "\n",
        "        if df_numeric.empty:\n",
        "            return {\"error\": \"No numeric columns found to generate a correlation heatmap.\"}\n",
        "        if len(df_numeric.columns) < 2:\n",
        "             return {\"error\": \"At least two numeric columns are required for a correlation heatmap.\"}\n",
        "\n",
        "        corr_matrix = df_numeric.corr()\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "        plt.title('Correlation Heatmap')\n",
        "        \n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format=\"png\")\n",
        "        plt.close() # Close the plot to free memory\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "        buf.close()\n",
        "\n",
        "        return {\"plot_type\": \"correlation_heatmap\", \"image_base64\": image_base64}\n",
        "\n",
        "    except Exception as e:\n",
        "        plt.close() # Ensure plot is closed in case of error during generation\n",
        "        return {\"error\": f\"Failed to generate correlation heatmap: {str(e)}\"}\n",
        "\n",
        "visualization_tools.append(create_correlation_heatmap)\n",
        "\n",
        "@tool\n",
        "def create_box_plot(df_id: str, column_name: str, group_by_column: Optional[str] = None) -> dict:\n",
        "    \"\"\"Generates a box plot for a specified numeric column, optionally grouped by another column.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the numeric column for the box plot values.\n",
        "        group_by_column: Optional. The name of the column to group by.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the plot type ('box_plot'), value column,\n",
        "        group by column (if any), and a base64 encoded PNG image,\n",
        "        or an error message dictionary if generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return {\"error\": f\"DataFrame with ID '{df_id}' not found.\"}\n",
        "\n",
        "        if column_name not in df.columns:\n",
        "            return {\"error\": f\"Value column '{column_name}' not found in DataFrame '{df_id}'.\"}\n",
        "\n",
        "        if not pd.api.types.is_numeric_dtype(df[column_name]):\n",
        "            return {\"error\": f\"Value column '{column_name}' is not numeric.\"}\n",
        "\n",
        "        plt.figure(figsize=(12, 8)) # Adjusted figure size for potential groups\n",
        "        plot_title = f'Box Plot of {column_name}'\n",
        "\n",
        "        if group_by_column:\n",
        "            if group_by_column not in df.columns:\n",
        "                return {\"error\": f\"Group by column '{group_by_column}' not found in DataFrame '{df_id}'.\"}\n",
        "            sns.boxplot(x=df[group_by_column], y=df[column_name])\n",
        "            plot_title += f' grouped by {group_by_column}'\n",
        "        else:\n",
        "            sns.boxplot(y=df[column_name])\n",
        "        \n",
        "        plt.title(plot_title)\n",
        "        plt.xlabel(group_by_column if group_by_column else column_name)\n",
        "        plt.ylabel(column_name)\n",
        "        plt.xticks(rotation=45, ha='right') # Rotate x-axis labels if grouped by categorical data\n",
        "        plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format=\"png\")\n",
        "        plt.close() # Close the plot to free memory\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "        buf.close()\n",
        "\n",
        "        return {\n",
        "            \"plot_type\": \"box_plot\", \n",
        "            \"value_column\": column_name, \n",
        "            \"group_by_column\": group_by_column, \n",
        "            \"image_base64\": image_base64\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        plt.close() # Ensure plot is closed in case of error during generation\n",
        "        return {\"error\": f\"Failed to generate box plot: {str(e)}\"}\n",
        "\n",
        "visualization_tools.append(create_box_plot)\n",
        "\n",
        "@tool\n",
        "def export_dataframe(df_id: str, file_name: str, file_format: str) -> str:\n",
        "    \"\"\"Exports a DataFrame to a file (CSV, Excel, or JSON) in the working directory.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        file_name: The desired name for the output file (e.g., 'my_data', 'report').\n",
        "                   The correct extension (.csv, .xlsx, .json) will be appended based on format.\n",
        "        file_format: The format to export to. Supported: 'csv', 'excel', 'json'.\n",
        "\n",
        "    Returns:\n",
        "        A success message with the path to the saved file,\n",
        "        or an error message if export fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return f\"Error: DataFrame with ID '{df_id}' not found.\"\n",
        "\n",
        "        # Ensure file_name does not have path components and prepare the full path\n",
        "        base_name = Path(file_name).name # Sanitize to prevent path traversal\n",
        "        \n",
        "        if file_format == 'csv':\n",
        "            actual_file_name = f\"{Path(base_name).stem}.csv\"\n",
        "            full_path = WORKING_DIRECTORY / actual_file_name\n",
        "            df.to_csv(full_path, index=False)\n",
        "        elif file_format == 'excel':\n",
        "            actual_file_name = f\"{Path(base_name).stem}.xlsx\"\n",
        "            full_path = WORKING_DIRECTORY / actual_file_name\n",
        "            df.to_excel(full_path, index=False)\n",
        "        elif file_format == 'json':\n",
        "            actual_file_name = f\"{Path(base_name).stem}.json\"\n",
        "            full_path = WORKING_DIRECTORY / actual_file_name\n",
        "            df.to_json(full_path, orient='records', indent=4)\n",
        "        else:\n",
        "            return f\"Error: Unsupported file format '{file_format}'. Supported formats are 'csv', 'excel', 'json'.\"\n",
        "\n",
        "        return f\"DataFrame '{df_id}' successfully exported to '{str(full_path)}' as {file_format}.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Failed to export DataFrame '{df_id}' to {file_format}: {str(e)}\"\n",
        "\n",
        "analyst_tools.append(export_dataframe)\n",
        "file_writer_tools.append(export_dataframe)\n",
        "data_cleaning_tools.append(export_dataframe)\n",
        "\n",
        "@tool\n",
        "def detect_and_remove_duplicates(df_id: str) -> str:\n",
        "    \"\"\"Detects and removes duplicate rows from a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "\n",
        "    Returns:\n",
        "        A message summarizing the number of duplicates found and removed,\n",
        "        or an error message if the operation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return f\"Error: DataFrame with ID '{df_id}' not found.\"\n",
        "\n",
        "        num_duplicates = df.duplicated().sum()\n",
        "\n",
        "        if num_duplicates == 0:\n",
        "            return f\"No duplicate rows found in DataFrame '{df_id}'.\"\n",
        "\n",
        "        original_row_count = len(df)\n",
        "        df_no_duplicates = df.drop_duplicates(keep='first', inplace=False) # Ensure a new DataFrame is returned\n",
        "        rows_removed = original_row_count - len(df_no_duplicates)\n",
        "\n",
        "        # Update the DataFrame in the registry\n",
        "        # The raw_path is kept from the original registration, implying the in-memory df is the target of de-duplication.\n",
        "        # If the de-duplicated df needs to be saved back to this raw_path, an explicit save (e.g., df_no_duplicates.to_csv(...)) would be needed.\n",
        "        # For now, we are updating the in-memory representation.\n",
        "        original_raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "        global_df_registry.register_dataframe(df_no_duplicates, df_id=df_id, raw_path=original_raw_path)\n",
        "\n",
        "        return f\"Found {num_duplicates} duplicate rows. Removed {rows_removed} rows. DataFrame '{df_id}' updated in memory.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during duplicate detection/removal for DataFrame '{df_id}': {str(e)}\"\n",
        "\n",
        "data_cleaning_tools.append(detect_and_remove_duplicates)\n",
        "\n",
        "@tool\n",
        "def convert_data_types(df_id: str, column_types: dict) -> str:\n",
        "    \"\"\"Converts specified columns in a DataFrame to new data types.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_types: A dictionary where keys are column names and values are\n",
        "                      the target data type strings (e.g., 'int', 'float', 'datetime64[ns]').\n",
        "\n",
        "    Returns:\n",
        "        A message summarizing the successful and failed data type conversions,\n",
        "        or an error message if the DataFrame is not found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return f\"Error: DataFrame with ID '{df_id}' not found.\"\n",
        "\n",
        "        df_copy = df.copy()\n",
        "        successful_conversions = []\n",
        "        failed_conversions = []\n",
        "        any_conversion_made = False\n",
        "\n",
        "        for column_name, new_type_str in column_types.items():\n",
        "            if column_name not in df_copy.columns:\n",
        "                failed_conversions.append(f\"{column_name} (column not found)\")\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                # Special handling for 'boolean' as pandas uses 'bool'\n",
        "                if new_type_str.lower() == 'boolean':\n",
        "                    new_type_str = 'bool'\n",
        "                \n",
        "                # For numeric types, attempt to clean non-convertible values to NaN first\n",
        "                if new_type_str in ['int', 'float', 'int64', 'float64']:\n",
        "                    df_copy[column_name] = pd.to_numeric(df_copy[column_name], errors='coerce')\n",
        "                \n",
        "                df_copy[column_name] = df_copy[column_name].astype(new_type_str)\n",
        "                successful_conversions.append(f\"{column_name} to {new_type_str}\")\n",
        "                any_conversion_made = True\n",
        "            except (ValueError, TypeError) as e:\n",
        "                failed_conversions.append(f\"{column_name} to {new_type_str} (Error: {e})\")\n",
        "            except Exception as e: # Catch any other unexpected errors during conversion\n",
        "                failed_conversions.append(f\"{column_name} to {new_type_str} (Unexpected error: {e})\")\n",
        "\n",
        "        if any_conversion_made:\n",
        "            original_raw_path = global_df_registry.get_raw_path_from_id(df_id)\n",
        "            global_df_registry.register_dataframe(df_copy, df_id=df_id, raw_path=original_raw_path)\n",
        "            summary_message = f\"Data type conversions applied for DataFrame '{df_id}'.\"\n",
        "        else:\n",
        "            summary_message = f\"No data type conversions made for DataFrame '{df_id}'.\"\n",
        "        \n",
        "        if successful_conversions:\n",
        "            summary_message += \" Success: [\" + \", \".join(successful_conversions) + \"].\"\n",
        "        if failed_conversions:\n",
        "            summary_message += \" Failed: [\" + \", \".join(failed_conversions) + \"].\"\n",
        "            \n",
        "        return summary_message\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during data type conversion process for DataFrame '{df_id}': {str(e)}\"\n",
        "\n",
        "data_cleaning_tools.append(convert_data_types)\n",
        "\n",
        "@tool\n",
        "def generate_html_report(report_title: str, text_sections: Dict[str, str], image_sections: Dict[str, str]) -> str:\n",
        "    \"\"\"Generates an HTML report from text and image sections and saves it to a file.\n",
        "\n",
        "    Args:\n",
        "        report_title: The main title for the report.\n",
        "        text_sections: A dictionary where keys are section titles (e.g., \"Data Description\") \n",
        "                       and values are the corresponding text content (can be multiline).\n",
        "        image_sections: A dictionary where keys are section titles (e.g., \"Histogram of Age\") \n",
        "                        and values are base64 encoded PNG image strings.\n",
        "\n",
        "    Returns:\n",
        "        A success message with the path to the saved HTML report file,\n",
        "        or an error message if generation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        html_content = f\"\"\"<html>\n",
        "<head><title>{report_title}</title></head>\n",
        "<body>\n",
        "<h1>{report_title}</h1>\n\"\"\"\n",
        "\n",
        "        for title, text in text_sections.items():\n",
        "            html_content += f\"<h2>{title}</h2>\\n<p>{text.replace('\\n', '<br>')}</p>\\n\"\n",
        "\n",
        "        for title, base64_image_string in image_sections.items():\n",
        "            html_content += f\"<h2>{title}</h2>\\n\"\n",
        "            html_content += f'<img src=\"data:image/png;base64,{base64_image_string}\" alt=\"{title}\" style=\"max-width:100%;height:auto;\">\\n'\n",
        "\n",
        "        html_content += \"</body>\\n</html>\"\n",
        "\n",
        "        safe_title = \"\".join(c if c.isalnum() else \"_\" for c in report_title)\n",
        "        file_name = f\"{safe_title}_report.html\"\n",
        "        full_path = WORKING_DIRECTORY / file_name\n",
        "\n",
        "        with open(full_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        return f\"HTML report generated: '{str(full_path)}'\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Failed to generate HTML report: {str(e)}\"\n",
        "\n",
        "report_generator_tools.append(generate_html_report)\n",
        "\n",
        "@tool\n",
        "def calculate_correlation_matrix(df_id: str, column_names: Optional[List[str]] = None) -> str:\n",
        "    \"\"\"Calculates the correlation matrix for numeric columns in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_names: Optional. A list of column names to include in the calculation.\n",
        "                      If None or empty, all numeric columns will be used.\n",
        "\n",
        "    Returns:\n",
        "        A JSON string representing the correlation matrix,\n",
        "        or an error message string (as JSON) if calculation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return json.dumps({\"error\": f\"DataFrame with ID '{df_id}' not found.\"})\n",
        "\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        if column_names:\n",
        "            # Validate provided column names\n",
        "            missing_cols = [col for col in column_names if col not in df_copy.columns]\n",
        "            if missing_cols:\n",
        "                return json.dumps({\"error\": f\"Columns not found in DataFrame: {', '.join(missing_cols)}.\"})\n",
        "            df_to_correlate = df_copy[column_names]\n",
        "        else:\n",
        "            df_to_correlate = df_copy\n",
        "\n",
        "        df_numeric = df_to_correlate.select_dtypes(include=np.number)\n",
        "\n",
        "        if df_numeric.empty:\n",
        "            return json.dumps({\"error\": \"No numeric columns found to calculate correlation matrix.\"})\n",
        "        if len(df_numeric.columns) < 2:\n",
        "            return json.dumps({\"error\": \"At least two numeric columns are required to calculate a correlation matrix.\"})\n",
        "\n",
        "        corr_matrix = df_numeric.corr()\n",
        "        return corr_matrix.to_json(orient='index')\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to calculate correlation matrix: {str(e)}\"})\n",
        "\n",
        "analyst_tools.append(calculate_correlation_matrix)\n",
        "\n",
        "@tool\n",
        "def detect_outliers(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"Detects outliers in a numeric column of a DataFrame using the IQR method.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the numeric column to check for outliers.\n",
        "\n",
        "    Returns:\n",
        "        A JSON string summarizing the outlier detection findings (IQR, bounds,\n",
        "        number of outliers, sample of outliers) or a message if no outliers are found.\n",
        "        Returns a JSON string with an error message if the operation fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return json.dumps({\"error\": f\"DataFrame with ID '{df_id}' not found.\"})\n",
        "\n",
        "        if column_name not in df.columns:\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' not found in DataFrame '{df_id}'.\"})\n",
        "\n",
        "        s = df[column_name]\n",
        "        if not pd.api.types.is_numeric_dtype(s):\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' must be numeric to detect outliers using IQR.\"})\n",
        "\n",
        "        Q1 = s.quantile(0.25)\n",
        "        Q3 = s.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        outliers = s[(s < lower_bound) | (s > upper_bound)]\n",
        "\n",
        "        if not outliers.empty:\n",
        "            return json.dumps({\n",
        "                \"column\": column_name,\n",
        "                \"iqr\": IQR,\n",
        "                \"lower_bound\": lower_bound,\n",
        "                \"upper_bound\": upper_bound,\n",
        "                \"num_outliers\": len(outliers),\n",
        "                \"outliers_sample\": outliers.head().tolist() # Convert sample to list for JSON serialization\n",
        "            })\n",
        "        else:\n",
        "            return json.dumps({\n",
        "                \"column\": column_name, \n",
        "                \"message\": \"No outliers detected using IQR method.\",\n",
        "                \"iqr\": IQR,\n",
        "                \"lower_bound\": lower_bound,\n",
        "                \"upper_bound\": upper_bound\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to detect outliers: {str(e)}\"})\n",
        "\n",
        "analyst_tools.append(calculate_correlation_matrix)\n",
        "\n",
        "@tool\n",
        "def perform_normality_test(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"Performs a Shapiro-Wilk normality test on a numeric column.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the numeric column to test.\n",
        "\n",
        "    Returns:\n",
        "        A JSON string with the test statistic, p-value, and interpretation,\n",
        "        or an error message string (as JSON) if the test cannot be performed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return json.dumps({\"error\": f\"DataFrame with ID '{df_id}' not found.\"})\n",
        "\n",
        "        if column_name not in df.columns:\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' not found in DataFrame '{df_id}'.\"})\n",
        "\n",
        "        s = df[column_name].dropna()\n",
        "        if not pd.api.types.is_numeric_dtype(s):\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' must be numeric for normality testing.\"})\n",
        "\n",
        "        if not (3 <= len(s) < 5000):\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' must contain between 3 and 4999 non-null samples for Shapiro-Wilk test. Found {len(s)}.\"})\n",
        "\n",
        "        stat, p_value = stats.shapiro(s)\n",
        "        alpha = 0.05\n",
        "        is_normal = p_value > alpha\n",
        "        interpretation = \"Data looks Gaussian (fail to reject H0)\" if is_normal else \"Data does not look Gaussian (reject H0)\"\n",
        "\n",
        "        return json.dumps({\n",
        "            \"column\": column_name,\n",
        "            \"test_type\": \"Shapiro-Wilk\",\n",
        "            \"statistic\": stat,\n",
        "            \"p_value\": p_value,\n",
        "            \"is_normal\": is_normal,\n",
        "            \"interpretation\": interpretation\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to perform normality test: {str(e)}\"})\n",
        "\n",
        "analyst_tools.append(detect_outliers)\n",
        "\n",
        "@tool\n",
        "def perform_normality_test(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"Performs a Shapiro-Wilk normality test on a numeric column.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the numeric column to test.\n",
        "\n",
        "    Returns:\n",
        "        A JSON string with the test statistic, p-value, and interpretation,\n",
        "        or an error message string (as JSON) if the test cannot be performed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return json.dumps({\"error\": f\"DataFrame with ID '{df_id}' not found.\"})\n",
        "\n",
        "        if column_name not in df.columns:\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' not found in DataFrame '{df_id}'.\"})\n",
        "\n",
        "        s = df[column_name].dropna()\n",
        "        if not pd.api.types.is_numeric_dtype(s):\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' must be numeric for normality testing.\"})\n",
        "\n",
        "        # Shapiro-Wilk test is typically suitable for sample sizes between 3 and 5000.\n",
        "        if not (3 <= len(s) < 5000):\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' must contain between 3 and 4999 non-null samples for Shapiro-Wilk test. Found {len(s)}.\"})\n",
        "\n",
        "        stat, p_value = stats.shapiro(s)\n",
        "        alpha = 0.05\n",
        "        is_normal = p_value > alpha\n",
        "        interpretation = \"Data looks Gaussian (fail to reject H0)\" if is_normal else \"Data does not look Gaussian (reject H0)\"\n",
        "\n",
        "        return json.dumps({\n",
        "            \"column\": column_name,\n",
        "            \"test_type\": \"Shapiro-Wilk\",\n",
        "            \"statistic\": stat,\n",
        "            \"p_value\": p_value,\n",
        "            \"is_normal\": is_normal,\n",
        "            \"interpretation\": interpretation\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to perform normality test: {str(e)}\"})\n",
        "\n",
        "analyst_tools.append(perform_normality_test)\n",
        "\n",
        "@tool\n",
        "def assess_data_quality(df_id: str) -> str:\n",
        "    \"\"\"Provides a comprehensive data quality assessment for a DataFrame.\n",
        "\n",
        "    Checks for shape, missing values, data types, duplicate rows, and memory usage.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "\n",
        "    Returns:\n",
        "        A JSON string summarizing the data quality assessment,\n",
        "        or an error message string (as JSON) if the assessment fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return json.dumps({\"error\": f\"DataFrame with ID '{df_id}' not found.\"})\n",
        "\n",
        "        quality_report = {}\n",
        "\n",
        "        # Basic Info\n",
        "        quality_report[\"shape\"] = {\"rows\": int(df.shape[0]), \"columns\": int(df.shape[1])}\n",
        "\n",
        "        # Missing Values\n",
        "        missing_info = df.isnull().sum()\n",
        "        quality_report[\"missing_values_summary\"] = missing_info[missing_info > 0].astype(int).to_dict()\n",
        "        quality_report[\"total_missing_values\"] = int(missing_info.sum())\n",
        "        total_cells = df.shape[0] * df.shape[1]\n",
        "        quality_report[\"percentage_missing\"] = (quality_report[\"total_missing_values\"] / total_cells) * 100 if total_cells > 0 else 0\n",
        "\n",
        "        # Data Types\n",
        "        quality_report[\"data_types\"] = df.dtypes.astype(str).to_dict()\n",
        "\n",
        "        # Duplicate Rows\n",
        "        num_duplicates = df.duplicated().sum()\n",
        "        quality_report[\"duplicate_rows\"] = {\n",
        "            \"count\": int(num_duplicates),\n",
        "            \"percentage\": (int(num_duplicates) / df.shape[0]) * 100 if df.shape[0] > 0 else 0\n",
        "        }\n",
        "\n",
        "        # Memory Usage\n",
        "        memory_usage_bytes = df.memory_usage(deep=True).sum()\n",
        "        quality_report[\"memory_usage\"] = f\"{memory_usage_bytes / (1024**2):.2f} MB\"\n",
        "\n",
        "        return json.dumps(quality_report, indent=4, default=str) # Use default=str for numpy types\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to assess data quality: {str(e)}\"})\n",
        "\n",
        "analyst_tools.append(assess_data_quality)\n",
        "data_cleaning_tools.append(assess_data_quality) # Also useful for data cleaning stage\n",
        "\n",
        "@tool\n",
        "def perform_normality_test(df_id: str, column_name: str) -> str:\n",
        "    \"\"\"Performs a Shapiro-Wilk normality test on a numeric column.\n",
        "\n",
        "    Args:\n",
        "        df_id: The ID of the DataFrame in the global registry.\n",
        "        column_name: The name of the numeric column to test.\n",
        "\n",
        "    Returns:\n",
        "        A JSON string with the test statistic, p-value, and interpretation,\n",
        "        or an error message string (as JSON) if the test cannot be performed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = global_df_registry.get_dataframe(df_id)\n",
        "        if df is None:\n",
        "            return json.dumps({\"error\": f\"DataFrame with ID '{df_id}' not found.\"})\n",
        "\n",
        "        if column_name not in df.columns:\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' not found in DataFrame '{df_id}'.\"})\n",
        "\n",
        "        s = df[column_name].dropna()\n",
        "        if not pd.api.types.is_numeric_dtype(s):\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' must be numeric for normality testing.\"})\n",
        "\n",
        "        # Shapiro-Wilk test is typically suitable for sample sizes between 3 and 4999.\n",
        "        if not (3 <= len(s) < 5000):\n",
        "            return json.dumps({\"error\": f\"Column '{column_name}' must contain between 3 and 4999 non-null samples for Shapiro-Wilk test. Found {len(s)}.\"})\n",
        "\n",
        "        stat, p_value = stats.shapiro(s)\n",
        "        alpha = 0.05\n",
        "        is_normal = p_value > alpha\n",
        "        interpretation = \"Data looks Gaussian (fail to reject H0)\" if is_normal else \"Data does not look Gaussian (reject H0)\"\n",
        "\n",
        "        return json.dumps({\n",
        "            \"column\": column_name,\n",
        "            \"test_type\": \"Shapiro-Wilk\",\n",
        "            \"statistic\": stat,\n",
        "            \"p_value\": p_value,\n",
        "            \"is_normal\": is_normal,\n",
        "            \"interpretation\": interpretation\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to perform normality test: {str(e)}\"})\n",
        "\n",
        "analyst_tools.append(perform_normality_test)\n",
        "\n",
        "@tool\n",
        "def search_web_for_context(query: str, max_results: int = 3) -> str:\n",
        "    \"\"\"Performs a web search using Tavily API to find external context or insights.\n",
        "\n",
        "    Args:\n",
        "        query: The search query string.\n",
        "        max_results: The maximum number of search results to return (default is 3).\n",
        "\n",
        "    Returns:\n",
        "        A JSON string containing a list of search results (each with title, url, content),\n",
        "        or a JSON string with an error message if the search fails or API key is missing.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tavily_api_key = os.environ.get('TAVILY_API_KEY')\n",
        "        if not tavily_api_key:\n",
        "            return json.dumps({\"error\": \"TAVILY_API_KEY not found in environment variables.\"})\n",
        "        \n",
        "        client = TavilyClient(api_key=tavily_api_key)\n",
        "        # Use search_depth=\"advanced\" for more comprehensive results if needed, basic is faster.\n",
        "        response = client.search(query=query, search_depth=\"basic\", max_results=max_results)\n",
        "        \n",
        "        # Extract relevant parts of the results\n",
        "        formatted_results = []\n",
        "        if \"results\" in response:\n",
        "            for res in response[\"results\"]:\n",
        "                formatted_results.append({\n",
        "                    \"title\": res.get(\"title\"),\n",
        "                    \"url\": res.get(\"url\"),\n",
        "                    \"content\": res.get(\"content\")\n",
        "                })\n",
        "        return json.dumps(formatted_results, indent=4)\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Failed to perform web search: {str(e)}\"})\n",
        "\n",
        "analyst_tools.append(search_web_for_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBguFhuoZV5G"
      },
      "outputs": [],
      "source": [
        "in_memory_store = InMemoryStore()\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=oai_key) # oai_key from cell 1\n",
        "\n",
        "def create_data_cleaner_agent(initial_description:str, df_ids:List[str] = []) -> BaseChatModel:\n",
        "  checkpointer = MemorySaver()\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in data_cleaning_tools])\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      SystemMessage(content=data_cleaner_prompt_template.format(tool_descriptions=tool_descriptions, output_format=CleaningMetadata.model_json_schema(), dataset_description=initial_description, data_sample=None, available_df_ids=df_ids)),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "  ])\n",
        "  return create_react_agent(llm, tools=[*data_cleaning_tools], state_schema=State, checkpointer=checkpointer,store = in_memory_store,response_format= CleaningMetadata,prompt=prompt, name= \"data_cleaner\", version=\"v2\")\n",
        "\n",
        "def create_initial_analysis_agent(user_prompt:str, df_ids:List[str] = []) -> BaseChatModel:\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      SystemMessage(content=analyst_prompt_template_initial.format(tool_descriptions=tool_descriptions, output_format=InitialDescription.model_json_schema(), user_prompt=user_prompt, available_df_ids=df_ids)),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "  ])\n",
        "  checkpointer = MemorySaver()\n",
        "  return create_react_agent(llm, tools=analyst_tools, state_schema=State,checkpointer=checkpointer, store = in_memory_store,response_format= InitialDescription,prompt=prompt, name= \"initial_analysis\", version=\"v2\")\n",
        "\n",
        "def create_analyst_agent(initial_description:str, df_ids:List[str] = []) -> BaseChatModel:\n",
        "  checkpointer = MemorySaver()\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      SystemMessage(content=analyst_prompt_template_main.format(tool_descriptions=tool_descriptions, output_format=AnalysisInsights.model_json_schema(), cleaned_dataset_description=initial_description, cleaning_metadata=None, available_df_ids=df_ids)),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "  ])\n",
        "  return create_react_agent(llm, tools=analyst_tools, state_schema=State, response_format= AnalysisInsights,checkpointer=checkpointer,store = in_memory_store,prompt=prompt, name= \"analyst\", version=\"v2\")\n",
        "\n",
        "def create_file_writer_agent() -> BaseChatModel:\n",
        "  # tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in file_writer_tools]) # Not used in original\n",
        "  return create_react_agent(llm, tools=file_writer_tools, state_schema=State, checkpointer=MemorySaver(),store = in_memory_store)\n",
        "\n",
        "def create_visualization_agent(df_ids:List[str] = []) -> BaseChatModel:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in visualization_tools])\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "            SystemMessage(content=visualization_prompt_template.format(tool_descriptions=tool_descriptions, output_format=VisualizationResults.model_json_schema(), cleaned_dataset_description=\"\", analysis_insights=\"\", available_df_ids=df_ids)),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ])\n",
        "    checkpointer = MemorySaver()\n",
        "    return create_react_agent(llm, tools=[*visualization_tools], state_schema=State, checkpointer=checkpointer, store=in_memory_store, response_format=VisualizationResults, prompt=prompt, name=\"visualization\", version=\"v2\")\n",
        "\n",
        "def create_report_generator_agent(df_ids:List[str] = []) -> BaseChatModel:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in report_generator_tools])\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "            SystemMessage(content=report_generator_prompt_template.format(tool_descriptions=tool_descriptions, output_format=ReportResults.model_json_schema(), cleaning_metadata=\"\", analysis_insights=\"\", visualization_results=\"\", available_df_ids=df_ids)),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ])\n",
        "    checkpointer = MemorySaver()\n",
        "    return create_react_agent(llm, tools=[*report_generator_tools], state_schema=State, checkpointer=checkpointer, store=in_memory_store, response_format=ReportResults, prompt=prompt, name=\"report_generator\", version=\"v2\")\n",
        "\n",
        "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    namespace = (user_id, \"memories\")\n",
        "    memory_id = str(uuid.uuid4())\n",
        "    store.put(namespace, memory_id, {\"memory\": state[\"messages\"][-1].content})\n",
        "\n",
        "def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n",
        "    options = [\"FINISH\"] + members\n",
        "    system_prompt = (\n",
        "        \"You are a supervisor tasked with managing a conversation between the\"\n",
        "        f\" following workers: {members}. Given the following user request,\"\n",
        "        \" respond with the worker to act next. Each worker will perform a\"\n",
        "        \" task and respond with their results and status. When finished,\"\n",
        "        \" respond with FINISH.\"\n",
        "    )\n",
        "    class Router(TypedDict):\n",
        "        next: Literal[*options]\n",
        "\n",
        "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
        "        _count_ = state.get(\"_count_\", 0) + 1\n",
        "        state[\"_count_\"] = _count_\n",
        "        completed_str_parts = []\n",
        "        agent_bool_map = {\n",
        "            \"initial_analysis\": state.get(\"initial_analysis_complete\", False),\n",
        "            \"data_cleaner\": state.get(\"data_cleaning_complete\", False),\n",
        "            \"analyst\": state.get(\"analyst_complete\", False),\n",
        "            \"file_writer\": state.get(\"file_writer_complete\", False),\n",
        "            \"visualization\": state.get(\"visualization_complete\", False),\n",
        "            \"report_generator\": state.get(\"report_generator_complete\", False),\n",
        "        }\n",
        "        for agent_name, is_complete in agent_bool_map.items():\n",
        "            if is_complete:\n",
        "                completed_str_parts.append(f\"{agent_name} is complete, so dont pass to {agent_name} again.\")\n",
        "        \n",
        "        current_system_prompt = system_prompt\n",
        "        if completed_str_parts:\n",
        "            current_system_prompt += \"\\n\" + \"\\n\".join(completed_str_parts)\n",
        "            \n        messages = [SystemMessage(content=current_system_prompt)] + state[\"messages\"]\n",
        "        response = llm.with_structured_output(Router).invoke(messages, state[\"_config\"])\n",
        "        goto = response[\"next\"]\n",
        "        if goto == \"FINISH\":\n",
        "            goto = END\n",
        "\n",
        "        print(f\"Coordinator node: current state keys: {list(state.keys())}. Current count: {_count_}\")\n",
        "        # No need to manually create update_dict, LangGraph handles state updates from Command\n",
        "        print(f\"\\nCoordinator node: routing to: {goto} \\n\")\n",
        "        update_memory(state, state[\"_config\"], store=in_memory_store)\n",
        "        return Command(goto=goto)\n",
        "    return supervisor_node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSLpBrTN3FIy"
      },
      "outputs": [],
      "source": [
        "# Download sample dataset from Kagglehub\n",
        "# Imports: pprint, os, pandas as pd, kagglehub are in essential_imports_cell\n",
        "\n",
        "# !pip install kagglehub # Already in first cell\n",
        "\n",
        "path = kagglehub.dataset_download(\"datafiniti/consumer-reviews-of-amazon-products\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "raw_path_str = os.path.join(path, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
        "pprint(raw_path_str)\n",
        "\n",
        "df = None\n",
        "ext = os.path.splitext(raw_path_str)[-1].lower()\n",
        "try:\n",
        "    if ext == \".csv\":\n",
        "        df = pd.read_csv(raw_path_str)\n",
        "    elif ext == \".json\":\n",
        "        df = pd.read_json(raw_path_str)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please use CSV or JSON.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading file: {e}\")\n",
        "    raise\n",
        "\n",
        "df_name = \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products\"\n",
        "df_id = global_df_registry.register_dataframe(df, df_name, raw_path_str)\n",
        "\n",
        "sample_prompt_text = f\"Please analyze the dataset named {df_name}. You have tools available to you for accessing the data using the following str as the df_id parameter: `{df_id}`.\"\n",
        "sample_prompt_tuple = (\"user\", sample_prompt_text)\n",
        "pprint(sample_prompt_tuple)\n",
        "\n",
        "# Agent Instantiations\n",
        "data_cleaner_agent = create_data_cleaner_agent(initial_description=sample_prompt_text, df_ids=[df_id])\n",
        "initial_analysis_agent = create_initial_analysis_agent(user_prompt=sample_prompt_text, df_ids=[df_id])\n",
        "analyst_agent = create_analyst_agent(initial_description=sample_prompt_text, df_ids=[df_id])\n",
        "file_writer_agent = create_file_writer_agent()\n",
        "visualization_agent = create_visualization_agent(df_ids=[df_id])\n",
        "report_generator_agent = create_report_generator_agent(df_ids=[df_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixJqmfH0lBfE"
      },
      "outputs": [],
      "source": [
        "# Node Functions\n",
        "def initial_analysis_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "    output_format = InitialDescription.model_json_schema()\n",
        "    \n",
        "    msgs = trim_messages(state[\"messages\"],max_tokens=1000,token_counter=len) # Increased token limit\n",
        "    system_message_content = analyst_prompt_template_initial.format(tool_descriptions=tool_descriptions, output_format=output_format, user_prompt=state[\"user_prompt\"], available_df_ids=state[\"df_ids\"])\n",
        "    \n",
        "    # Replace or add system message carefully\n",
        "    final_msgs = [msg for msg in msgs if not isinstance(msg, SystemMessage)]\n",
        "    final_msgs.insert(0, SystemMessage(content=system_message_content))\n",
        "\n",
        "    # Memory retrieval (optional, if needed and configured)\n",
        "    # namespace = (state[\"_config\"][\"configurable\"][\"user_id\"], \"memories\")\n",
        "    # memories = in_memory_store.search(namespace, query=state[\"messages\"][-1].content, limit=3)\n",
        "    # info = \"\\n\".join([d.value[\"memory\"] for d in memories])\n",
        "\n",
        "    result = initial_analysis_agent.invoke({\"messages\":final_msgs}, config=state[\"_config\"]) # Pass config\n",
        "    print(f\"Initial analysis result: {result}\")\n",
        "    update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"initial_analysis\")],\"initial_description\": result[\"structured_response\"], \"initial_analysis_complete\": True}\n",
        "    return Command(update=update, goto=\"supervisor\")\n",
        "\n",
        "def data_cleaner_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "  tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in data_cleaning_tools])\n",
        "  output_format = CleaningMetadata.model_json_schema()\n",
        "  msgs = trim_messages(state[\"messages\"],max_tokens=1000,token_counter=len)\n",
        "  system_message_content = data_cleaner_prompt_template.format(tool_descriptions=tool_descriptions, output_format=output_format, dataset_description=state[\"initial_description\"].dataset_description, data_sample=state[\"initial_description\"].data_sample, available_df_ids=state[\"df_ids\"])\n",
        "  final_msgs = [msg for msg in msgs if not isinstance(msg, SystemMessage)]\n",
        "  final_msgs.insert(0, SystemMessage(content=system_message_content))\n",
        "  \n",
        "  result = data_cleaner_agent.invoke({\"messages\":final_msgs}, config=state[\"_config\"])\n",
        "  pprint(result)\n",
        "  update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"data_cleaner\")],\"cleaning_metadata\": result[\"structured_response\"], \"data_cleaning_complete\": True}\n",
        "  return Command(update=update, goto=\"supervisor\")\n",
        "\n",
        "def analyst_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in analyst_tools])\n",
        "    output_format = AnalysisInsights.model_json_schema()\n",
        "    msgs = trim_messages(state[\"messages\"],max_tokens=1000,token_counter=len)\n",
        "    system_message_content = analyst_prompt_template_main.format(tool_descriptions=tool_descriptions, output_format=output_format, cleaned_dataset_description=state[\"cleaning_metadata\"].data_description_after_cleaning, cleaning_metadata=state[\"cleaning_metadata\"], available_df_ids=state[\"df_ids\"])\n",
        "    final_msgs = [msg for msg in msgs if not isinstance(msg, SystemMessage)]\n",
        "    final_msgs.insert(0, SystemMessage(content=system_message_content))\n",
        "\n",
        "    result = analyst_agent.invoke({\"messages\":final_msgs}, config=state[\"_config\"])\n",
        "    pprint(f\"Analyst result: {result}\")\n",
        "    update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"analyst\")],\"analysis_insights\": result[\"structured_response\"], \"analyst_complete\": True}\n",
        "    return Command(update=update, goto=\"supervisor\")\n",
        "\n",
        "def file_writer_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    # This node's prompt logic might need to be more dynamic based on what needs writing\n",
        "    # For now, assuming state['user_prompt'] or a specific field in state contains file_name, content, file_type\n",
        "    # tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in file_writer_tools])\n",
        "    # This node was not using a specific prompt template in the agent creation, so direct invocation\n",
        "    result = file_writer_agent.invoke(state[\"messages\"], config=state[\"_config\"]) # Pass messages directly or format based on expected input\n",
        "    pprint(f\"File writer result: {result}\")\n",
        "    # Assuming result structure matches AgentState and has a 'messages' and potentially a structured_response for file_writer_complete\n",
        "    update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"file_writer\")], \"file_writer_complete\": True} # Mark as complete\n",
        "    return Command(update=update, goto=\"supervisor\")\n",
        "\n",
        "def visualization_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in visualization_tools])\n",
        "    output_format = VisualizationResults.model_json_schema()\n",
        "    msgs = trim_messages(state[\"messages\"], max_tokens=1000, token_counter=len)\n",
        "    system_message_content = visualization_prompt_template.format(tool_descriptions=tool_descriptions, output_format=output_format, cleaned_dataset_description=state[\"cleaning_metadata\"].data_description_after_cleaning, analysis_insights=state[\"analysis_insights\"], available_df_ids=state[\"df_ids\"])\n",
        "    final_msgs = [msg for msg in msgs if not isinstance(msg, SystemMessage)]\n",
        "    final_msgs.insert(0, SystemMessage(content=system_message_content))\n",
        "\n",
        "    result = visualization_agent.invoke({\"messages\": final_msgs}, config=state[\"_config\"])\n",
        "    pprint(f\"Visualization result: {result}\")\n",
        "    update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"visualization\")], \"visualization_results\": result[\"structured_response\"], \"visualization_complete\": True}\n",
        "    return Command(update=update, goto=\"supervisor\")\n",
        "\n",
        "def report_generator_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in report_generator_tools])\n",
        "    output_format = ReportResults.model_json_schema()\n",
        "    msgs = trim_messages(state[\"messages\"], max_tokens=1000, token_counter=len)\n",
        "    system_message_content = report_generator_prompt_template.format(tool_descriptions=tool_descriptions, output_format=output_format, cleaning_metadata=state[\"cleaning_metadata\"], analysis_insights=state[\"analysis_insights\"], visualization_results=state[\"visualization_results\"], available_df_ids=state[\"df_ids\"])\n",
        "    final_msgs = [msg for msg in msgs if not isinstance(msg, SystemMessage)]\n",
        "    final_msgs.insert(0, SystemMessage(content=system_message_content))\n",
        "\n",
        "    result = report_generator_agent.invoke({\"messages\": final_msgs}, config=state[\"_config\"])\n",
        "    pprint(f\"Report generator result: {result}\")\n",
        "    update = {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"report_generator\")], \"report_results\": result[\"structured_response\"], \"report_generator_complete\": True}\n",
        "    return Command(update=update, goto=\"supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v52mP2CxPj4"
      },
      "outputs": [],
      "source": [
        "coordinator_node = make_supervisor_node(llm, [\"initial_analysis\", \"data_cleaner\", \"analyst\", \"file_writer\", \"visualization\", \"report_generator\"])\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\",\"user_id\": \"user-1\"},\"recursion_limit\": 150}\n",
        "\n",
        "data_analysis_team_builder = StateGraph(State)\n",
        "checkpointer = MemorySaver() # Ensure this is the same instance if used by agents for shared memory, or None if agents manage their own.\n",
        "\n",
        "data_analysis_team_builder.add_node(\"supervisor\", coordinator_node)\n",
        "data_analysis_team_builder.add_node(\"initial_analysis\", initial_analysis_node)\n",
        "data_analysis_team_builder.add_node(\"data_cleaner\", data_cleaner_node)\n",
        "data_analysis_team_builder.add_node(\"analyst\", analyst_node)\n",
        "data_analysis_team_builder.add_node(\"file_writer\", file_writer_node)\n",
        "data_analysis_team_builder.add_node(\"visualization\", visualization_node)\n",
        "data_analysis_team_builder.add_node(\"report_generator\", report_generator_node)\n",
        "\n",
        "data_analysis_team_builder.add_edge(START, \"supervisor\")\n",
        "data_analysis_team_builder.add_edge(\"initial_analysis\", \"supervisor\")\n",
        "data_analysis_team_builder.add_edge(\"data_cleaner\", \"supervisor\")\n",
        "data_analysis_team_builder.add_edge(\"analyst\", \"supervisor\")\n",
        "data_analysis_team_builder.add_edge(\"file_writer\", \"supervisor\")\n",
        "data_analysis_team_builder.add_edge(\"visualization\", \"supervisor\")\n",
        "data_analysis_team_builder.add_edge(\"report_generator\", \"supervisor\")\n",
        "\n",
        "data_detective_graph = data_analysis_team_builder.compile(checkpointer=checkpointer, store=in_memory_store) # store was used in agent creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFTXS7s3x4Y3"
      },
      "outputs": [],
      "source": [
        "display(Image(data_detective_graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "combined_streaming_cells"
      },
      "outputs": [],
      "source": [
        "# Original Cell 11 (8D0coE-3QW11) - commented out astream_events\n",
        "# async for event in data_detective_graph.astream_events(\n",
        "#     {\"messages\": [sample_prompt_tuple], \"user_prompt\":sample_prompt_text,\"_config\":config, \"df_ids\":[df_id]},config,stream_mode=\"debug\",subgraphs=True, debug=True, version=\"v2\"):\n",
        "#     kind = event[\"event\"]\n",
        "#     # ... (rest of the original commented code)\n",
        "\n",
        "# Original Cell 13 (Mvg52ebjIn0_)\n",
        "received_chunks = []\n",
        "sample_prompt_final_human = HumanMessage(content=sample_prompt_text, name=\"user\") # Ensure it's a HumanMessage\n",
        "\n",
        "try:\n",
        "    for s_chunk in data_detective_graph.stream(\n",
        "        {\"messages\": [sample_prompt_final_human], \"user_prompt\":sample_prompt_text, \"_config\":config, \"df_ids\":[df_id]},\n",
        "        config,\n",
        "        stream_mode=\"updates\", # or \"values\" or \"debug\"\n",
        "        # subgraphs=True, # subgraphs might not be a param for stream, check docs if error\n",
        "        # debug=False\n",
        "    ):\n",
        "        pprint(s_chunk)\n",
        "        print(\"\\n\")\n",
        "        received_chunks.append(s_chunk)\n",
        "except Exception as e:\n",
        "    pprint(f\"Streaming Error: {e}\")\n",
        "    pprint(f\"Received chunks before error: {received_chunks}\")\n",
        "\n",
        "pprint(list(data_detective_graph.get_state_history(config)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBK-Q-qH9yas"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    last_state_history = data_detective_graph.get_state_history(config)\n",
        "    if last_state_history:\n",
        "        last_state = last_state_history[-1] # Get the most recent state snapshot\n",
        "        print(\"\\nFinal State Snapshot:\")\n",
        "        # pprint(last_state.values) # .values might be more appropriate for State object\n",
        "        \n",
        "        # Safely access keys, as they might not be present in all states\n",
        "        final_insights = last_state.values.get('analysis_insights')\n",
        "        if final_insights:\n",
        "            pprint(f\"Analyst result summary: {final_insights.summary}\")\n",
        "            pprint(f\"Analyst result correlation_insights: {final_insights.correlation_insights}\")\n",
        "            pprint(f\"Analyst result anomaly_insights: {final_insights.anomaly_insights}\")\n",
        "            pprint(f\"Analyst result recommended_visualizations: {final_insights.recommended_visualizations}\")\n",
        "        else:\n",
        "            print(\"Analysis insights not found in the final state.\")\n",
        "        \n",
        "        final_report_results = last_state.values.get('report_results')\n",
        "        if final_report_results:\n",
        "            pprint(f\"Report results: {final_report_results.report_path}\")\n",
        "        else:\n",
        "            print(\"Report results not found in the final state.\")\n",
        "    else:\n",
        "        print(\"No state history found.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error accessing final state: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pydantic_test_cell"
      },
      "outputs": [],
      "source": [
        "from pydantic import ValidationError\n",
        "print(\"Testing GetDataParams Pydantic model:\")\n",
        "try:\n",
        "    print(GetDataParams(df_id='test', index=0, columns='all'))\n",
        "    print(GetDataParams(df_id='test', index=[0,1], columns='all'))\n",
        "    print(GetDataParams(df_id='test', index=(0,2), columns='all'))\n",
        "    for invalid_index in ['invalid', (1,), [1,'a']]:\n",
        "        try:\n",
        "            GetDataParams(df_id='test', index=invalid_index, columns='all')\n",
        "        except ValidationError as e:\n",
        "            print(f\"Caught expected ValidationError for index={invalid_index}: {e}\")\n",
        "except NameError as ne:\n",
        "    print(f\"Pydantic models (GetDataParams) not defined yet or error in definition: {ne}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unittest_dataframe_registry_cell"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "import shutil # For cleaning up test directory if needed, though TemporaryDirectory handles it\n",
        "\n",
        "# Ensure PatchedDataFrameRegistry is defined if it's different from DataFrameRegistry\n",
        "# For now, assuming DataFrameRegistry is the one to test and is defined.\n",
        "\n",
        "class TestDataFrameRegistry(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        # Each test gets its own temporary directory and registry instance\n",
        "        self.test_temp_dir = TemporaryDirectory()\n",
        "        self.test_working_dir = Path(self.test_temp_dir.name)\n",
        "        \n",
        "        # Temporarily patch global WORKING_DIRECTORY for this test suite\n",
        "        global WORKING_DIRECTORY\n",
        "        self.original_working_directory = WORKING_DIRECTORY\n",
        "        WORKING_DIRECTORY = self.test_working_dir\n",
        "        \n",
        "        self.registry = DataFrameRegistry(capacity=2)\n",
        "        self.sample_df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
        "        self.sample_df2 = pd.DataFrame({'C': [5, 6], 'D': [7, 8]})\n",
        "        self.sample_df3 = pd.DataFrame({'E': [9, 10], 'F': [11, 12]})\n",
        "\n",
        "        self.test_csv_path = self.test_working_dir / \"test_load.csv\"\n",
        "        self.sample_df_for_csv = pd.DataFrame({'X': [100, 200]})\n",
        "        self.sample_df_for_csv.to_csv(self.test_csv_path, index=False)\n",
        "\n",
        "    def tearDown(self):\n",
        "        global WORKING_DIRECTORY\n",
        "        WORKING_DIRECTORY = self.original_working_directory # Restore original\n",
        "        self.test_temp_dir.cleanup() # Explicitly clean up temp dir\n",
        "\n",
        "    def test_register_and_get_dataframe(self):\n",
        "        df_id1 = self.registry.register_dataframe(self.sample_df1, \"df1\")\n",
        "        self.assertEqual(df_id1, \"df1\")\n",
        "        retrieved_df1 = self.registry.get_dataframe(\"df1\")\n",
        "        pd.testing.assert_frame_equal(retrieved_df1, self.sample_df1)\n",
        "        self.assertIn(\"df1\", self.registry.cache)\n",
        "\n",
        "    def test_get_dataframe_not_exists(self):\n",
        "        retrieved_df = self.registry.get_dataframe(\"non_existent_df\")\n",
        "        self.assertIsNone(retrieved_df)\n",
        "\n",
        "    def test_remove_dataframe(self):\n",
        "        self.registry.register_dataframe(self.sample_df1, \"df1\")\n",
        "        self.registry.remove_dataframe(\"df1\")\n",
        "        self.assertNotIn(\"df1\", self.registry.registry)\n",
        "        self.assertNotIn(\"df1\", self.registry.cache)\n",
        "        self.assertNotIn(\"df1\", self.registry.df_id_to_raw_path)\n",
        "\n",
        "    def test_cache_lru_eviction(self):\n",
        "        self.registry.register_dataframe(self.sample_df1, \"df1\")\n",
        "        self.registry.register_dataframe(self.sample_df2, \"df2\")\n",
        "        self.registry.get_dataframe(\"df1\") # Access df1 to make it most recently used\n",
        "        self.registry.register_dataframe(self.sample_df3, \"df3\")\n",
        "        self.assertIn(\"df1\", self.registry.cache)\n",
        "        self.assertIn(\"df3\", self.registry.cache)\n",
        "        self.assertNotIn(\"df2\", self.registry.cache)\n",
        "\n",
        "    def test_get_raw_path_from_id(self):\n",
        "        raw_path_str = str(self.test_working_dir / \"custom_path.csv\")\n",
        "        df_id = self.registry.register_dataframe(self.sample_df1, \"df_custom\", raw_path=raw_path_str)\n",
        "        retrieved_path = self.registry.get_raw_path_from_id(df_id)\n",
        "        self.assertEqual(retrieved_path, raw_path_str)\n",
        "\n",
        "    def test_get_dataframe_load_if_not_exists(self):\n",
        "        df_id_load = self.registry.register_dataframe(df=None, df_id=\"df_load\", raw_path=str(self.test_csv_path))\n",
        "        self.assertNotIn(df_id_load, self.registry.cache)\n",
        "        loaded_df = self.registry.get_dataframe(df_id_load, load_if_not_exists=True)\n",
        "        self.assertIsNotNone(loaded_df)\n",
        "        pd.testing.assert_frame_equal(loaded_df, self.sample_df_for_csv)\n",
        "        self.assertIn(df_id_load, self.registry.cache)\n",
        "\n",
        "    def test_get_dataframe_load_if_not_exists_file_not_found(self):\n",
        "        df_id_missing = self.registry.register_dataframe(df=None, df_id=\"df_missing\", raw_path=str(self.test_working_dir / \"non_existent.csv\"))\n",
        "        loaded_df = self.registry.get_dataframe(df_id_missing, load_if_not_exists=True)\n",
        "        self.assertIsNone(loaded_df)\n",
        "\n",
        "print(\"Running DataFrameRegistry tests...\")\n",
        "suite = unittest.TestSuite()\n",
        "suite.addTest(unittest.TestLoader().loadTestsFromTestCase(TestDataFrameRegistry))\n",
        "runner = unittest.TextTestRunner(verbosity=2)\n",
        "result = runner.run(suite)\n",
        "print(\"Tests completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgRwWoBT3bpU"
      },
      "outputs": [],
      "source": [
        "# Imports from original cell 15\n",
        "from functools import cache\n",
        "from io import BytesIO\n",
        "# from google.colab import drive # Not needed if not on Colab / driving mounting\n",
        "import ipywidgets as widgets\n",
        "# from IPython.display import display, clear_output # display already imported"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
